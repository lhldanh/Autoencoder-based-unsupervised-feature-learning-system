{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fTKcxHDDoIe",
        "outputId": "b22bc054-bfc8-471e-8d18-3bc63985c456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stt58Qna-O09",
        "outputId": "cca2fdff-34af-4eef-fa98-947d21fadb5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Tài liệu HCMUS/Năm 4/ltss/Doan\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/\"Tài liệu HCMUS\"/'Năm 4'/ltss/Doan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptsf8xVWF_JJ",
        "outputId": "616d87b8-a00f-400d-a5a8-bcec4f90b096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Tài liệu HCMUS/Năm 4/ltss/Doan/Autoencoder-based-unsupervised-feature-learning-system\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/lhldanh/Autoencoder-based-unsupervised-feature-learning-system.git\n",
        "%cd Autoencoder-based-unsupervised-feature-learning-system/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0a0ff136"
      },
      "outputs": [],
      "source": [
        "%mkdir -p build\n",
        "%mkdir -p weights\n",
        "%mkdir -p data\n",
        "# !wget https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz -O data/cifar-10-binary.tar.gz\n",
        "# !tar -xzvf data/cifar-10-binary.tar.gz -C data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOEubgcjB64H",
        "outputId": "aa26478b-16e5-448a-f2cd-fa628574c199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "build  data  include  README.md  src  train_gpu_optimize  weights\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njgQkXrK_k_1",
        "outputId": "cced8b29-51bf-4662-a967-b7280a6b92b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "from numba import cuda\n",
        "major, minor = cuda.get_current_device().compute_capability\n",
        "print(f'GPU compute capability: {major}.{minor}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtZItoPTFQEa"
      },
      "source": [
        "## writefile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TYk5AwYIYjL",
        "outputId": "db7ec237-69c6-42d7-c353-d9b21727cfa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/train_gpu.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/train_gpu_optimize.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <random>\n",
        "#include <algorithm>\n",
        "#include <fstream>\n",
        "#include <chrono>\n",
        "#include <cmath>   // For sqrt\n",
        "#include \"cifar10_dataset.h\"\n",
        "#include \"kernels.h\" // Assuming this includes ConvParam_G struct\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h> // For malloc/free\n",
        "\n",
        "// Assuming ConvParam_G is defined in kernels.h or provided elsewhere.\n",
        "// For the purpose of making the code compile, I'll define a placeholder:\n",
        "struct ConvParam_G {\n",
        "    int B, H_in, W_in, C_in;\n",
        "    int H_out, W_out, C_out;\n",
        "    int K, S, P;\n",
        "};\n",
        "\n",
        "\n",
        "void check_cuda(cudaError_t result, char const *const func, const char *const file, int const line) {\n",
        "  if (result) {\n",
        "    fprintf(stderr, \"CUDA error at %s:%d code=%d (%s) \\\"%s\\\" \\n\", file, line, static_cast<unsigned int>(result), cudaGetErrorString(result), func);\n",
        "    exit(EXIT_FAILURE);\n",
        "  }\n",
        "}\n",
        "\n",
        "// Utility for CUDA error checking\n",
        "void checkCudaErrors(cudaError_t code) {\n",
        "  if (code != cudaSuccess) {\n",
        "    std::cerr << \"CUDA Error: \" << cudaGetErrorString(code) << \" (Code: \" << code << \")\\n\";\n",
        "    exit(code);\n",
        "  }\n",
        "}\n",
        "\n",
        "// --- DEVICE-SIDE HELPER FUNCTIONS ---\n",
        "\n",
        "// Function executed on the GPU to calculate the index.\n",
        "__device__ inline int get_idx_dev(int b, int h, int w, int c, int H, int W, int C) {\n",
        "  return b * (H * W * C) + h * (W * C) + w * C + c;\n",
        "}\n",
        "\n",
        "// Helper to zero out memory (Crucial for backward passes that use atomicAdd or accumulation)\n",
        "__global__ void fill_zeros(float* data, size_t size) {\n",
        "  size_t idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (idx < size) data[idx] = 0.0f;\n",
        "}\n",
        "\n",
        "// --- KERNEL LAUNCH CONFIGURATION ---\n",
        "dim3 get_1d_dims(size_t total_size) {\n",
        "  const int THREADS_PER_BLOCK = 256;\n",
        "  // We cast total_size to int for division, assuming total_size fits within standard integer limits\n",
        "  // Use size_t and long long to avoid potential overflow issues with int casting\n",
        "  size_t blocks = (total_size + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n",
        "  return dim3((unsigned int)blocks, 1, 1);\n",
        "}\n",
        "\n",
        "// ====================================================================\n",
        "//             1. CONVOLUTION\n",
        "// ====================================================================\n",
        "\n",
        "// --- FORWARD KERNEL (Field names corrected to match ConvParam_G) ---\n",
        "__global__ void conv2d_kernel(float* input, float* weight, float* bias, float* output, ConvParam_G p) {\n",
        "  int out_idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int total_output_size = p.B * p.H_out * p.W_out * p.C_out;\n",
        "\n",
        "  if (out_idx < total_output_size) {\n",
        "    int C = p.C_out;\n",
        "    int W = p.W_out;\n",
        "    int H = p.H_out;\n",
        "\n",
        "    int oc = out_idx % C;\n",
        "    int temp = out_idx / C;\n",
        "    int ow = temp % W;\n",
        "    temp = temp / W;\n",
        "    int oh = temp % H;\n",
        "    int b = temp / H;\n",
        "\n",
        "    float sum = bias[oc];\n",
        "\n",
        "    // Iterate over input channels, kernel height, and width\n",
        "    for (int ic = 0; ic < p.C_in; ++ic) {\n",
        "      for (int kh = 0; kh < p.K; ++kh) {\n",
        "        for (int kw = 0; kw < p.K; ++kw) {\n",
        "          // Calculate input indices (ih, iw)\n",
        "          int ih = oh * p.S - p.P + kh;\n",
        "          int iw = ow * p.S - p.P + kw;\n",
        "\n",
        "          if (ih >= 0 && ih < p.H_in && iw >= 0 && iw < p.W_in) {\n",
        "            int in_idx = get_idx_dev(b, ih, iw, ic, p.H_in, p.W_in, p.C_in);\n",
        "\n",
        "            // Weight layout: [C_out][C_in][K][K]\n",
        "            int w_idx = oc * (p.C_in * p.K * p.K)\n",
        "                 + ic * (p.K * p.K)\n",
        "                 + kh * p.K + kw;\n",
        "\n",
        "            sum += input[in_idx] * weight[w_idx];\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    output[out_idx] = sum;\n",
        "  }\n",
        "}\n",
        "\n",
        "// --- BACKWARD KERNELS (Field names corrected) ---\n",
        "\n",
        "// 1. Calculate Gradients w.r.t Input (d_input)\n",
        "__global__ void conv2d_backward_input_kernel(float* d_output, float* weight, float* d_input, ConvParam_G p) {\n",
        "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int total_in_size = p.B * p.H_in * p.W_in * p.C_in;\n",
        "\n",
        "  if (idx < total_in_size) {\n",
        "    int c = idx % p.C_in;\n",
        "    int temp = idx / p.C_in;\n",
        "    int w = temp % p.W_in;\n",
        "    temp = temp / p.W_in;\n",
        "    int h = temp % p.H_in;\n",
        "    int b = temp / p.H_in;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // Iterate over output channels and kernel window\n",
        "    for (int oc = 0; oc < p.C_out; ++oc) {\n",
        "      for (int kh = 0; kh < p.K; ++kh) {\n",
        "        for (int kw = 0; kw < p.K; ++kw) {\n",
        "          // Logic to find the output pixel that this input pixel contributed to\n",
        "          // This is essentially reverse mapping the convolution indices.\n",
        "          int h_shifted = h + p.P - kh;\n",
        "          int w_shifted = w + p.P - kw;\n",
        "\n",
        "          if (h_shifted % p.S == 0 && w_shifted % p.S == 0) {\n",
        "            int oh = h_shifted / p.S;\n",
        "            int ow = w_shifted / p.S;\n",
        "\n",
        "            if (oh >= 0 && oh < p.H_out && ow >= 0 && ow < p.W_out) {\n",
        "              int out_idx = get_idx_dev(b, oh, ow, oc, p.H_out, p.W_out, p.C_out);\n",
        "\n",
        "              // Weight layout: [C_out][C_in][K][K]\n",
        "              int w_idx = oc * (p.C_in * p.K * p.K)\n",
        "                   + c * (p.K * p.K)\n",
        "                   + kh * p.K + kw;\n",
        "              sum += d_output[out_idx] * weight[w_idx];\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    d_input[idx] = sum;\n",
        "  }\n",
        "}\n",
        "\n",
        "// 2. Calculate Gradients w.r.t Weights (d_weight)\n",
        "__global__ void conv2d_backward_weight_kernel(float* d_output, float* input, float* d_weight, ConvParam_G p) {\n",
        "  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int total_weights = p.C_out * p.C_in * p.K * p.K;\n",
        "\n",
        "  if (idx < total_weights) {\n",
        "    int kw = idx % p.K;\n",
        "    int temp = idx / p.K;\n",
        "    int kh = temp % p.K;\n",
        "    temp = temp / p.K;\n",
        "    int ic = temp % p.C_in;\n",
        "    int oc = temp / p.C_in;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // Sum gradients over the entire batch and image spatial dimensions\n",
        "    for (int b = 0; b < p.B; ++b) {\n",
        "      for (int oh = 0; oh < p.H_out; ++oh) {\n",
        "        for (int ow = 0; ow < p.W_out; ++ow) {\n",
        "          int ih = oh * p.S - p.P + kh;\n",
        "          int iw = ow * p.S - p.P + kw;\n",
        "          if (ih >= 0 && ih < p.H_in && iw >= 0 && iw < p.W_in) {\n",
        "            int in_idx = get_idx_dev(b, ih, iw, ic, p.H_in, p.W_in, p.C_in);\n",
        "            int out_idx = get_idx_dev(b, oh, ow, oc, p.H_out, p.W_out, p.C_out);\n",
        "            sum += input[in_idx] * d_output[out_idx];\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    d_weight[idx] = sum;\n",
        "  }\n",
        "}\n",
        "\n",
        "// 3. Calculate Gradients w.r.t Bias (d_bias)\n",
        "__global__ void conv2d_backward_bias_kernel(float* d_output, float* d_bias, ConvParam_G p) {\n",
        "  int oc = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (oc < p.C_out) {\n",
        "    float sum = 0.0f;\n",
        "    for (int b = 0; b < p.B; ++b) {\n",
        "      for (int h = 0; h < p.H_out; ++h) {\n",
        "        for (int w = 0; w < p.W_out; ++w) {\n",
        "          int out_idx = get_idx_dev(b, h, w, oc, p.H_out, p.W_out, p.C_out);\n",
        "          sum += d_output[out_idx];\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    d_bias[oc] = sum;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "// ====================================================================\n",
        "//             2. ReLU ACTIVATION\n",
        "// ====================================================================\n",
        "\n",
        "__global__ void relu_kernel(float* data, size_t size) {\n",
        "  size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < size) {\n",
        "    data[i] = (data[i] < 0.0f) ? 0.0f : data[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__ void relu_backward_kernel(float* d_output, float* input, float* d_input, size_t size) {\n",
        "  size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < size) {\n",
        "    // dL/dx = dL/dy * dy/dx. dy/dx = 1 if x > 0, 0 otherwise.\n",
        "    d_input[i] = (input[i] > 0) ? d_output[i] : 0.0f;\n",
        "  }\n",
        "}\n",
        "\n",
        "// ====================================================================\n",
        "//             3. MAX POOLING\n",
        "// ====================================================================\n",
        "\n",
        "// --- FORWARD KERNEL ---\n",
        "__global__ void maxpool_kernel(float* input, float* output, int batch, int in_h, int in_w, int in_c) {\n",
        "  int out_idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int out_h = in_h / 2;\n",
        "  int out_w = in_w / 2;\n",
        "  int total_output_size = batch * out_h * out_w * in_c;\n",
        "  int stride = 2;\n",
        "\n",
        "  if (out_idx < total_output_size) {\n",
        "    int C = in_c;\n",
        "    int W = out_w;\n",
        "    int H = out_h;\n",
        "\n",
        "    int c = out_idx % C;\n",
        "    int temp = out_idx / C;\n",
        "    int ow = temp % W;\n",
        "    temp = temp / W;\n",
        "    int oh = temp % H;\n",
        "    int b = temp / H;\n",
        "\n",
        "    float max_val = -1e9;\n",
        "\n",
        "    for (int kh = 0; kh < 2; ++kh) {\n",
        "      for (int kw = 0; kw < 2; ++kw) {\n",
        "        int ih = oh * stride + kh;\n",
        "        int iw = ow * stride + kw;\n",
        "        int in_idx = get_idx_dev(b, ih, iw, c, in_h, in_w, in_c);\n",
        "        if (input[in_idx] > max_val) max_val = input[in_idx];\n",
        "      }\n",
        "    }\n",
        "    output[out_idx] = max_val;\n",
        "  }\n",
        "}\n",
        "\n",
        "// --- BACKWARD KERNEL ---\n",
        "__global__ void maxpool_backward_kernel(float* d_output, float* input, float* d_input,\n",
        "                    int batch, int in_h, int in_w, int in_c) {\n",
        "  int out_idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int out_h = in_h / 2;\n",
        "  int out_w = in_w / 2;\n",
        "  int total_output = batch * out_h * out_w * in_c;\n",
        "\n",
        "  // Only thread for an output gradient (d_output) needs to run\n",
        "  if (out_idx < total_output) {\n",
        "    int c = out_idx % in_c;\n",
        "    int temp = out_idx / in_c;\n",
        "    int ow = temp % out_w;\n",
        "    temp = temp / out_w;\n",
        "    int oh = temp % out_h;\n",
        "    int b = temp / out_h;\n",
        "\n",
        "    int start_h = oh * 2;\n",
        "    int start_w = ow * 2;\n",
        "    float max_val = -1e9;\n",
        "    int max_idx = -1;\n",
        "\n",
        "    // Re-find the max value position\n",
        "    for (int kh = 0; kh < 2; ++kh) {\n",
        "      for (int kw = 0; kw < 2; ++kw) {\n",
        "        int ih = start_h + kh;\n",
        "        int iw = start_w + kw;\n",
        "        int in_idx = get_idx_dev(b, ih, iw, c, in_h, in_w, in_c);\n",
        "        float val = input[in_idx];\n",
        "        if (val > max_val) {\n",
        "          max_val = val;\n",
        "          max_idx = in_idx;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "    // Atomic add the gradient to the winner pixel. d_input must be zeroed beforehand.\n",
        "    if (max_idx != -1) {\n",
        "      atomicAdd(&d_input[max_idx], d_output[out_idx]);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "// ====================================================================\n",
        "//             4. UPSAMPLE\n",
        "// ====================================================================\n",
        "\n",
        "// --- FORWARD KERNEL ---\n",
        "__global__ void upsample_kernel(float* input, float* output, int batch, int in_h, int in_w, int in_c) {\n",
        "  int out_idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int out_h = in_h * 2;\n",
        "  int out_w = in_w * 2;\n",
        "  int total_output_size = batch * out_h * out_w * in_c;\n",
        "\n",
        "  if (out_idx < total_output_size) {\n",
        "    int C = in_c;\n",
        "    int W = out_w;\n",
        "    int H = out_h;\n",
        "\n",
        "    int c = out_idx % C;\n",
        "    int temp = out_idx / C;\n",
        "    int ow = temp % W;\n",
        "    temp = temp / W;\n",
        "    int oh = temp % H;\n",
        "    int b = temp / H;\n",
        "\n",
        "    int ih = oh / 2;\n",
        "    int iw = ow / 2;\n",
        "    int in_idx = get_idx_dev(b, ih, iw, c, in_h, in_w, in_c);\n",
        "    output[out_idx] = input[in_idx];\n",
        "  }\n",
        "}\n",
        "\n",
        "// --- BACKWARD KERNEL ---\n",
        "__global__ void upsample_backward_kernel(float* d_output, float* d_input,\n",
        "                    int batch, int in_h, int in_w, int in_c) {\n",
        "  // Note: in_h/in_w here refer to the input of the forward pass (small image)\n",
        "  int out_idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int out_h = in_h * 2;\n",
        "  int out_w = in_w * 2;\n",
        "  int total_output_size = batch * out_h * out_w * in_c;\n",
        "\n",
        "  if (out_idx < total_output_size) {\n",
        "    int C = in_c;\n",
        "    int W = out_w;\n",
        "    int H = out_h;\n",
        "\n",
        "    int c = out_idx % C;\n",
        "    int temp = out_idx / C;\n",
        "    int ow = temp % W;\n",
        "    temp = temp / W;\n",
        "    int oh = temp % H;\n",
        "    int b = temp / H;\n",
        "\n",
        "    // Map larger image pixel back to small image pixel\n",
        "    int ih = oh / 2;\n",
        "    int iw = ow / 2;\n",
        "    int in_idx = get_idx_dev(b, ih, iw, c, in_h, in_w, in_c);\n",
        "\n",
        "    // Atomic add required as 4 output pixels map to 1 input pixel. d_input must be zeroed beforehand.\n",
        "    atomicAdd(&d_input[in_idx], d_output[out_idx]);\n",
        "  }\n",
        "}\n",
        "\n",
        "// ====================================================================\n",
        "//             5. MSE LOSS\n",
        "// ====================================================================\n",
        "\n",
        "__global__ void mse_diff_kernel(float* pred, float* target, float* diff_sq, size_t size) {\n",
        "  size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < size) {\n",
        "    float diff = pred[i] - target[i];\n",
        "    diff_sq[i] = diff * diff;\n",
        "  }\n",
        "}\n",
        "\n",
        "// Backward kernel for MSE: dL/d(pred) = 2 * (pred - target) / N\n",
        "__global__ void mse_backward_kernel(float* pred, float* target, float* grad_out, size_t size) {\n",
        "  size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < size) {\n",
        "    // The gradient is (2 * difference) / size.\n",
        "    grad_out[i] = 2.0f * (pred[i] - target[i]) / size;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "float mse_loss_kernel(float* pred, float* target, size_t size) {\n",
        "  float* diff_sq_d;\n",
        "  checkCudaErrors(cudaMalloc((void**)&diff_sq_d, size * sizeof(float)));\n",
        "\n",
        "  mse_diff_kernel<<<get_1d_dims(size), 256>>>(pred, target, diff_sq_d, size);\n",
        "  checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "  // A more performant implementation would use CUB or a custom GPU reduction.\n",
        "  // For simplicity and avoiding external libraries, we do a host sync and sum.\n",
        "  float* diff_sq_h = (float*)malloc(size * sizeof(float));\n",
        "  checkCudaErrors(cudaMemcpy(diff_sq_h, diff_sq_d, size * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "\n",
        "  double sum = 0.0; // Use double for accumulation to prevent precision issues\n",
        "  for (size_t i = 0; i < size; ++i) {\n",
        "    sum += diff_sq_h[i];\n",
        "  }\n",
        "\n",
        "  checkCudaErrors(cudaFree(diff_sq_d));\n",
        "  free(diff_sq_h);\n",
        "\n",
        "  return (float)(sum / size);\n",
        "}\n",
        "\n",
        "// ====================================================================\n",
        "//             6. OPTIMIZER\n",
        "// ====================================================================\n",
        "\n",
        "__global__ void update_weights_kernel(float* weights, float* d_weights, size_t size, float lr) {\n",
        "  size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < size) {\n",
        "    weights[i] = weights[i] - lr * d_weights[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "// Utility for Xavier initialization\n",
        "void init_random(std::vector<float>& vec, int fan_in, int fan_out) {\n",
        "  std::random_device rd;\n",
        "  std::mt19937 gen(rd());\n",
        "  float limit = sqrt(6.0f / (fan_in + fan_out));\n",
        "  std::uniform_real_distribution<float> d(-limit, limit);\n",
        "  for (auto& x : vec) x = d(gen);\n",
        "}\n",
        "\n",
        "// Utility to save weights\n",
        "void save_weights(const std::string& filename, const std::vector<float>& data) {\n",
        "  std::ofstream file(filename, std::ios::binary);\n",
        "  if (file.is_open()) {\n",
        "    uint32_t size = data.size();\n",
        "    file.write(reinterpret_cast<const char*>(&size), sizeof(size));\n",
        "    file.write(reinterpret_cast<const char*>(data.data()), data.size() * sizeof(float));\n",
        "    file.close();\n",
        "  } else {\n",
        "    std::cerr << \"Error saving: \" << filename << \"\\n\";\n",
        "  }\n",
        "}\n",
        "\n",
        "// Helper to allocate and copy Host data to Device\n",
        "void allocate_and_copy(float*& device_ptr, const std::vector<float>& host_data) {\n",
        "  size_t size = host_data.size() * sizeof(float);\n",
        "  checkCudaErrors(cudaMalloc((void**)&device_ptr, size));\n",
        "  checkCudaErrors(cudaMemcpy(device_ptr, host_data.data(), size, cudaMemcpyHostToDevice));\n",
        "}\n",
        "\n",
        "// Helper for allocating device buffers (no initial copy needed)\n",
        "void allocate_device_buffer(float*& device_ptr, size_t size_elements) {\n",
        "  checkCudaErrors(cudaMalloc((void**)&device_ptr, size_elements * sizeof(float)));\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "  // 1. CONFIG & DATA\n",
        "  int BATCH = 512;\n",
        "  int EPOCHS = 10;\n",
        "  int MAX_IMAGES = 1024; // Limit number of images for quick testing\n",
        "  float LR = 0.001f;\n",
        "\n",
        "  std::string data_path = \"../data/cifar-10-batches-bin\";\n",
        "  CIFAR10Dataset dataset(data_path);\n",
        "  dataset.load_data();\n",
        "  if (dataset.get_num_train() == 0) return 1;\n",
        "\n",
        "  // --- HOST WEIGHTS AND BIASES ---\n",
        "    // Encoder: 32x32x3 -> Conv1 -> 32x32x256 -> MaxPool -> 16x16x256\n",
        "    // 16x16x256 -> Conv2 -> 16x16x128 -> MaxPool -> 8x8x128 (Latent)\n",
        "  std::vector<float> h_w1(256*3*3*3);   init_random(h_w1, 3*3*3, 256*3*3);\n",
        "  std::vector<float> h_b1(256, 0.0f);\n",
        "  std::vector<float> h_w2(128*256*3*3);  init_random(h_w2, 256*3*3, 128*3*3);\n",
        "  std::vector<float> h_b2(128, 0.0f);\n",
        "    // Decoder: 8x8x128 -> Conv3 -> 8x8x128 (Conv on latent to extract features)\n",
        "    // 8x8x128 -> Upsample -> 16x16x128 -> Conv4 -> 16x16x256\n",
        "    // 16x16x256 -> Upsample -> 32x32x256 -> Conv5 -> 32x32x3\n",
        "  std::vector<float> h_w3(128*128*3*3);  init_random(h_w3, 128*3*3, 128*3*3);\n",
        "  std::vector<float> h_b3(128, 0.0f);\n",
        "  std::vector<float> h_w4(256*128*3*3);  init_random(h_w4, 128*3*3, 256*3*3);\n",
        "  std::vector<float> h_b4(256, 0.0f);\n",
        "  std::vector<float> h_w5(3*256*3*3);   init_random(h_w5, 256*3*3, 3*3*3);\n",
        "  std::vector<float> h_b5(3, 0.0f);\n",
        "\n",
        "  // --- DEVICE POINTERS & SIZES ---\n",
        "  float *d_w1, *d_b1, *d_dw1, *d_db1;\n",
        "  float *d_w2, *d_b2, *d_dw2, *d_db2;\n",
        "  float *d_w3, *d_b3, *d_dw3, *d_db3;\n",
        "  float *d_w4, *d_b4, *d_dw4, *d_db4;\n",
        "  float *d_w5, *d_b5, *d_dw5, *d_db5;\n",
        "  float *d_input, *d_l1_out, *d_l1_pool, *d_l2_out, *d_latent;\n",
        "  float *d_l3_out, *d_l3_up, *d_l4_out, *d_l4_up, *d_final_out;\n",
        "  float *d_d_input, *d_d_l1_out, *d_d_l1_pool, *d_d_l2_out, *d_d_latent;\n",
        "  float *d_d_l3_out, *d_d_l3_up, *d_d_l4_out, *d_d_l4_up, *d_d_final_out;\n",
        "\n",
        "  size_t size_input  = (size_t)BATCH * 32 * 32 * 3;\n",
        "  size_t size_l1_out = (size_t)BATCH * 32 * 32 * 256;\n",
        "  size_t size_l1_pool = (size_t)BATCH * 16 * 16 * 256;\n",
        "  size_t size_l2_out = (size_t)BATCH * 16 * 16 * 128;\n",
        "  size_t size_latent = (size_t)BATCH * 8 * 8 * 128;\n",
        "    // Decoder output sizes\n",
        "    // d_l3_out is size_latent\n",
        "    size_t size_l3_up   = (size_t)BATCH * 16 * 16 * 128;\n",
        "    size_t size_l4_out  = (size_t)BATCH * 16 * 16 * 256;\n",
        "    size_t size_l4_up   = (size_t)BATCH * 32 * 32 * 256;\n",
        "\n",
        "\n",
        "  // 2. ALLOCATE AND COPY MEMORY\n",
        "  std::cout << \"Allocating and copying initial weights to GPU...\\n\";\n",
        "  allocate_and_copy(d_w1, h_w1); allocate_and_copy(d_b1, h_b1);\n",
        "  allocate_and_copy(d_w2, h_w2); allocate_and_copy(d_b2, h_b2);\n",
        "  allocate_and_copy(d_w3, h_w3); allocate_and_copy(d_b3, h_b3);\n",
        "  allocate_and_copy(d_w4, h_w4); allocate_and_copy(d_b4, h_b4);\n",
        "  allocate_and_copy(d_w5, h_w5); allocate_and_copy(d_b5, h_b5);\n",
        "\n",
        "  allocate_device_buffer(d_dw1, h_w1.size()); allocate_device_buffer(d_db1, h_b1.size());\n",
        "  allocate_device_buffer(d_dw2, h_w2.size()); allocate_device_buffer(d_db2, h_b2.size());\n",
        "  allocate_device_buffer(d_dw3, h_w3.size()); allocate_device_buffer(d_db3, h_b3.size());\n",
        "  allocate_device_buffer(d_dw4, h_w4.size()); allocate_device_buffer(d_db4, h_b4.size());\n",
        "  allocate_device_buffer(d_dw5, h_w5.size()); allocate_device_buffer(d_db5, h_b5.size());\n",
        "\n",
        "  allocate_device_buffer(d_input, size_input);\n",
        "  allocate_device_buffer(d_l1_out, size_l1_out);\n",
        "  allocate_device_buffer(d_l1_pool, size_l1_pool);\n",
        "  allocate_device_buffer(d_l2_out, size_l2_out);\n",
        "  allocate_device_buffer(d_latent, size_latent);\n",
        "  allocate_device_buffer(d_l3_out, size_latent);\n",
        "  allocate_device_buffer(d_l3_up, size_l3_up); // Fixed size\n",
        "  allocate_device_buffer(d_l4_out, size_l4_out); // Fixed size\n",
        "  allocate_device_buffer(d_l4_up, size_l4_up); // Fixed size\n",
        "  allocate_device_buffer(d_final_out, size_input);\n",
        "\n",
        "  allocate_device_buffer(d_d_input, size_input);\n",
        "  allocate_device_buffer(d_d_l1_out, size_l1_out);\n",
        "  allocate_device_buffer(d_d_l1_pool, size_l1_pool);\n",
        "  allocate_device_buffer(d_d_l2_out, size_l2_out);\n",
        "  allocate_device_buffer(d_d_latent, size_latent);\n",
        "  allocate_device_buffer(d_d_l3_out, size_latent);\n",
        "  allocate_device_buffer(d_d_l3_up, size_l3_up); // Fixed size\n",
        "  allocate_device_buffer(d_d_l4_out, size_l4_out); // Fixed size\n",
        "  allocate_device_buffer(d_d_l4_up, size_l4_up); // Fixed size\n",
        "  allocate_device_buffer(d_d_final_out, size_input);\n",
        "\n",
        "\n",
        "  // 3. TRAINING LOOP\n",
        "  std::cout << \"--- START FULL TRAINING (CUDA) ---\\n\";\n",
        "\n",
        "  // ConvParam_G: B, H_in, W_in, C_in, H_out, W_out, C_out, K, S, P\n",
        "    // Encoder\n",
        "  ConvParam_G p1 = {BATCH, 32, 32, 3,  32, 32, 256, 3, 1, 1}; // Output: 32x32x256\n",
        "  ConvParam_G p2 = {BATCH, 16, 16, 256, 16, 16, 128, 3, 1, 1}; // Output: 16x16x128\n",
        "    // Decoder\n",
        "  ConvParam_G p3 = {BATCH, 8, 8, 128,  8, 8, 128,  3, 1, 1}; // Output: 8x8x128 (Latent conv)\n",
        "  ConvParam_G p4 = {BATCH, 16, 16, 128, 16, 16, 256, 3, 1, 1}; // Output: 16x16x256\n",
        "  ConvParam_G p5 = {BATCH, 32, 32, 256, 32, 32, 3,  3, 1, 1}; // Output: 32x32x3\n",
        "\n",
        "  int num_batches = MAX_IMAGES / BATCH;\n",
        "  auto start_total = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "  for (int epoch = 0; epoch < EPOCHS; ++epoch) {\n",
        "    float total_loss = 0.0f;\n",
        "\n",
        "    for (int b = 0; b < num_batches; ++b) {\n",
        "      // A. Copy Batch to Device\n",
        "      size_t offset = (size_t)b * (size_input / BATCH) * BATCH;\n",
        "      checkCudaErrors(cudaMemcpy(d_input,\n",
        "                  dataset.get_train_images_ptr() + offset,\n",
        "                  size_input * sizeof(float),\n",
        "                  cudaMemcpyHostToDevice));\n",
        "\n",
        "      // B. FORWARD PASS (Direct Kernel Launches)\n",
        "      // Conv1 -> ReLU -> MaxPool (32->16)\n",
        "      conv2d_kernel<<<get_1d_dims(size_l1_out), 256>>>(d_input, d_w1, d_b1, d_l1_out, p1);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "      relu_kernel<<<get_1d_dims(size_l1_out), 256>>>(d_l1_out, size_l1_out);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "      maxpool_kernel<<<get_1d_dims(size_l1_pool), 256>>>(d_l1_out, d_l1_pool, BATCH, 32, 32, 256);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "      // Conv2 -> ReLU -> MaxPool (16->8)\n",
        "      conv2d_kernel<<<get_1d_dims(size_l2_out), 256>>>(d_l1_pool, d_w2, d_b2, d_l2_out, p2);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "      relu_kernel<<<get_1d_dims(size_l2_out), 256>>>(d_l2_out, size_l2_out);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "      maxpool_kernel<<<get_1d_dims(size_latent), 256>>>(d_l2_out, d_latent, BATCH, 16, 16, 128);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "      // Conv3 (Latent) -> ReLU -> Upsample (8->16)\n",
        "      conv2d_kernel<<<get_1d_dims(size_latent), 256>>>(d_latent, d_w3, d_b3, d_l3_out, p3);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "      relu_kernel<<<get_1d_dims(size_latent), 256>>>(d_l3_out, size_latent);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "      upsample_kernel<<<get_1d_dims(size_l3_up), 256>>>(d_l3_out, d_l3_up, BATCH, 8, 8, 128); // 8x8 to 16x16\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "      // Conv4 -> ReLU -> Upsample (16->32)\n",
        "      conv2d_kernel<<<get_1d_dims(size_l4_out), 256>>>(d_l3_up, d_w4, d_b4, d_l4_out, p4);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "      relu_kernel<<<get_1d_dims(size_l4_out), 256>>>(d_l4_out, size_l4_out);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "      upsample_kernel<<<get_1d_dims(size_l4_up), 256>>>(d_l4_out, d_l4_up, BATCH, 16, 16, 256); // 16x16 to 32x32\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "      // Conv5 (Final output)\n",
        "      conv2d_kernel<<<get_1d_dims(size_input), 256>>>(d_l4_up, d_w5, d_b5, d_final_out, p5);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "      // C. Loss (Assumed Host Wrapper with internal sync/copy)\n",
        "      float loss = mse_loss_kernel(d_final_out, d_input, size_input);\n",
        "      total_loss += loss;\n",
        "\n",
        "      // D. BACKWARD PASS (Direct Kernel Launches)\n",
        "\n",
        "            // 1. Final Output Gradient (MSE)\n",
        "      mse_backward_kernel<<<get_1d_dims(size_input), 256>>>(d_final_out, d_input, d_d_final_out, size_input);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "            // 2. Conv5 Backward\n",
        "            // Zero out gradient buffers for accumulation\n",
        "            fill_zeros<<<get_1d_dims(h_w5.size()), 256>>>(d_dw5, h_w5.size());\n",
        "            fill_zeros<<<get_1d_dims(h_b5.size()), 256>>>(d_db5, h_b5.size());\n",
        "            fill_zeros<<<get_1d_dims(size_l4_up), 256>>>(d_d_l4_up, size_l4_up); // d_input buffer\n",
        "\n",
        "      conv2d_backward_input_kernel<<<get_1d_dims(size_l4_up), 256>>>(d_d_final_out, d_w5, d_d_l4_up, p5); // d_input\n",
        "      conv2d_backward_weight_kernel<<<get_1d_dims(h_w5.size()), 256>>>(d_d_final_out, d_l4_up, d_dw5, p5); // d_weight\n",
        "      conv2d_backward_bias_kernel<<<get_1d_dims(h_b5.size()), 256>>>(d_d_final_out, d_db5, p5); // d_bias\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "            // 3. Upsample (32->16) Backward\n",
        "            fill_zeros<<<get_1d_dims(size_l4_out), 256>>>(d_d_l4_out, size_l4_out); // d_input buffer\n",
        "\n",
        "      upsample_backward_kernel<<<get_1d_dims(size_l4_up), 256>>>(d_d_l4_up, d_d_l4_out, BATCH, 16, 16, 256); // input_H=16, input_W=16\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "            // 4. Conv4 ReLU Backward\n",
        "      relu_backward_kernel<<<get_1d_dims(size_l4_out), 256>>>(d_d_l4_out, d_l4_out, d_d_l4_out, size_l4_out);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "            // 5. Conv4 Backward\n",
        "            fill_zeros<<<get_1d_dims(h_w4.size()), 256>>>(d_dw4, h_w4.size());\n",
        "            fill_zeros<<<get_1d_dims(h_b4.size()), 256>>>(d_db4, h_b4.size());\n",
        "            fill_zeros<<<get_1d_dims(size_l3_up), 256>>>(d_d_l3_up, size_l3_up); // d_input buffer\n",
        "\n",
        "      conv2d_backward_input_kernel<<<get_1d_dims(size_l3_up), 256>>>(d_d_l4_out, d_w4, d_d_l3_up, p4);\n",
        "      conv2d_backward_weight_kernel<<<get_1d_dims(h_w4.size()), 256>>>(d_d_l4_out, d_l3_up, d_dw4, p4);\n",
        "      conv2d_backward_bias_kernel<<<get_1d_dims(h_b4.size()), 256>>>(d_d_l4_out, d_db4, p4);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "            // 6. Upsample (16->8) Backward\n",
        "            fill_zeros<<<get_1d_dims(size_latent), 256>>>(d_d_l3_out, size_latent); // d_input buffer\n",
        "\n",
        "      upsample_backward_kernel<<<get_1d_dims(size_l3_up), 256>>>(d_d_l3_up, d_d_l3_out, BATCH, 8, 8, 128); // input_H=8, input_W=8\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "            // 7. Conv3 ReLU Backward\n",
        "      relu_backward_kernel<<<get_1d_dims(size_latent), 256>>>(d_d_l3_out, d_l3_out, d_d_l3_out, size_latent);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "            // 8. Conv3 Backward (Latent)\n",
        "            fill_zeros<<<get_1d_dims(h_w3.size()), 256>>>(d_dw3, h_w3.size());\n",
        "            fill_zeros<<<get_1d_dims(h_b3.size()), 256>>>(d_db3, h_b3.size());\n",
        "            fill_zeros<<<get_1d_dims(size_latent), 256>>>(d_d_latent, size_latent); // d_input buffer\n",
        "\n",
        "      conv2d_backward_input_kernel<<<get_1d_dims(size_latent), 256>>>(d_d_l3_out, d_w3, d_d_latent, p3);\n",
        "      conv2d_backward_weight_kernel<<<get_1d_dims(h_w3.size()), 256>>>(d_d_l3_out, d_latent, d_dw3, p3);\n",
        "      conv2d_backward_bias_kernel<<<get_1d_dims(h_b3.size()), 256>>>(d_d_l3_out, d_db3, p3);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "            // 9. MaxPool (16->8) Backward\n",
        "            fill_zeros<<<get_1d_dims(size_l2_out), 256>>>(d_d_l2_out, size_l2_out); // d_input buffer\n",
        "\n",
        "      maxpool_backward_kernel<<<get_1d_dims(size_latent), 256>>>(d_d_latent, d_l2_out, d_d_l2_out, BATCH, 16, 16, 128); // input_H=16, input_W=16\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "            // 10. Conv2 ReLU Backward\n",
        "      relu_backward_kernel<<<get_1d_dims(size_l2_out), 256>>>(d_d_l2_out, d_l2_out, d_d_l2_out, size_l2_out);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "            // 11. Conv2 Backward\n",
        "            fill_zeros<<<get_1d_dims(h_w2.size()), 256>>>(d_dw2, h_w2.size());\n",
        "            fill_zeros<<<get_1d_dims(h_b2.size()), 256>>>(d_db2, h_b2.size());\n",
        "            fill_zeros<<<get_1d_dims(size_l1_pool), 256>>>(d_d_l1_pool, size_l1_pool); // d_input buffer\n",
        "\n",
        "      conv2d_backward_input_kernel<<<get_1d_dims(size_l1_pool), 256>>>(d_d_l2_out, d_w2, d_d_l1_pool, p2);\n",
        "      conv2d_backward_weight_kernel<<<get_1d_dims(h_w2.size()), 256>>>(d_d_l2_out, d_l1_pool, d_dw2, p2);\n",
        "      conv2d_backward_bias_kernel<<<get_1d_dims(h_b2.size()), 256>>>(d_d_l2_out, d_db2, p2);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "            // 12. MaxPool (32->16) Backward\n",
        "            fill_zeros<<<get_1d_dims(size_l1_out), 256>>>(d_d_l1_out, size_l1_out); // d_input buffer\n",
        "\n",
        "      maxpool_backward_kernel<<<get_1d_dims(size_l1_pool), 256>>>(d_d_l1_pool, d_l1_out, d_d_l1_out, BATCH, 32, 32, 256); // input_H=32, input_W=32\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "            // 13. Conv1 ReLU Backward\n",
        "      relu_backward_kernel<<<get_1d_dims(size_l1_out), 256>>>(d_d_l1_out, d_l1_out, d_d_l1_out, size_l1_out);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "            // 14. Conv1 Backward\n",
        "            fill_zeros<<<get_1d_dims(h_w1.size()), 256>>>(d_dw1, h_w1.size());\n",
        "            fill_zeros<<<get_1d_dims(h_b1.size()), 256>>>(d_db1, h_b1.size());\n",
        "            fill_zeros<<<get_1d_dims(size_input), 256>>>(d_d_input, size_input); // d_input buffer (optional, likely discarded)\n",
        "\n",
        "      conv2d_backward_input_kernel<<<get_1d_dims(size_input), 256>>>(d_d_l1_out, d_w1, d_d_input, p1);\n",
        "      conv2d_backward_weight_kernel<<<get_1d_dims(h_w1.size()), 256>>>(d_d_l1_out, d_input, d_dw1, p1);\n",
        "      conv2d_backward_bias_kernel<<<get_1d_dims(h_b1.size()), 256>>>(d_d_l1_out, d_db1, p1);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "      // E. Update Weights\n",
        "      update_weights_kernel<<<get_1d_dims(h_w1.size()), 256>>>(d_w1, d_dw1, h_w1.size(), LR);\n",
        "      update_weights_kernel<<<get_1d_dims(h_b1.size()), 256>>>(d_b1, d_db1, h_b1.size(), LR);\n",
        "      update_weights_kernel<<<get_1d_dims(h_w2.size()), 256>>>(d_w2, d_dw2, h_w2.size(), LR);\n",
        "      update_weights_kernel<<<get_1d_dims(h_b2.size()), 256>>>(d_b2, d_db2, h_b2.size(), LR);\n",
        "      update_weights_kernel<<<get_1d_dims(h_w3.size()), 256>>>(d_w3, d_dw3, h_w3.size(), LR);\n",
        "      update_weights_kernel<<<get_1d_dims(h_b3.size()), 256>>>(d_b3, d_db3, h_b3.size(), LR);\n",
        "      update_weights_kernel<<<get_1d_dims(h_w4.size()), 256>>>(d_w4, d_dw4, h_w4.size(), LR);\n",
        "      update_weights_kernel<<<get_1d_dims(h_b4.size()), 256>>>(d_b4, d_db4, h_b4.size(), LR);\n",
        "      update_weights_kernel<<<get_1d_dims(h_w5.size()), 256>>>(d_w5, d_dw5, h_w5.size(), LR);\n",
        "      update_weights_kernel<<<get_1d_dims(h_b5.size()), 256>>>(d_b5, d_db5, h_b5.size(), LR);\n",
        "      checkCudaErrors(cudaGetLastError());\n",
        "    }\n",
        "\n",
        "    auto end_epoch = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> elapsed_epoch = end_epoch - start_total;\n",
        "\n",
        "    std::cout << \"\\nEpoch \" << epoch + 1 << \" Done. Avg Loss: \" << total_loss / num_batches\n",
        "          << \" | Time: \" << elapsed_epoch.count() << \"s\\n\";\n",
        "  } // End of epoch loop\n",
        "\n",
        "  auto end_total = std::chrono::high_resolution_clock::now();\n",
        "  std::chrono::duration<double> elapsed_total = end_total - start_total;\n",
        "  std::cout << \"\\n--- Training Complete ---\\n\";\n",
        "  std::cout << \"Total Training Time: \" << elapsed_total.count() << \" seconds\\n\";\n",
        "\n",
        "\n",
        "  // 4. COPY FINAL WEIGHTS BACK TO HOST & SAVE\n",
        "  std::cout << \"\\n--- Copying Final Weights to Host and Saving ---\\n\";\n",
        "\n",
        "  // Copy Weights back D -> H\n",
        "  checkCudaErrors(cudaMemcpy(h_w1.data(), d_w1, h_w1.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "  checkCudaErrors(cudaMemcpy(h_b1.data(), d_b1, h_b1.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "  checkCudaErrors(cudaMemcpy(h_w2.data(), d_w2, h_w2.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "  checkCudaErrors(cudaMemcpy(h_b2.data(), d_b2, h_b2.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "  checkCudaErrors(cudaMemcpy(h_w3.data(), d_w3, h_w3.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "  checkCudaErrors(cudaMemcpy(h_b3.data(), d_b3, h_b3.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "  checkCudaErrors(cudaMemcpy(h_w4.data(), d_w4, h_w4.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "  checkCudaErrors(cudaMemcpy(h_b4.data(), d_b4, h_b4.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "  checkCudaErrors(cudaMemcpy(h_w5.data(), d_w5, h_w5.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "  checkCudaErrors(cudaMemcpy(h_b5.data(), d_b5, h_b5.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "\n",
        "  // Save Weights (using the host save_weights utility function)\n",
        "  save_weights(\"../weights/enc_w1.bin\", h_w1); save_weights(\"../weights/enc_b1.bin\", h_b1);\n",
        "  save_weights(\"../weights/enc_w2.bin\", h_w2); save_weights(\"../weights/enc_b2.bin\", h_b2);\n",
        "  save_weights(\"../weights/dec_w3.bin\", h_w3); save_weights(\"../weights/dec_b3.bin\", h_b3);\n",
        "  save_weights(\"../weights/dec_w4.bin\", h_w4); save_weights(\"../weights/dec_b4.bin\", h_b4);\n",
        "  save_weights(\"../weights/dec_w5.bin\", h_w5); save_weights(\"../weights/dec_b5.bin\", h_b5);\n",
        "\n",
        "  // 5. CLEANUP DEVICE MEMORY\n",
        "  std::cout << \"\\n--- Cleaning up device memory ---\\n\";\n",
        "\n",
        "  // Free Weights and Gradients\n",
        "  cudaFree(d_w1); cudaFree(d_b1); cudaFree(d_dw1); cudaFree(d_db1);\n",
        "  cudaFree(d_w2); cudaFree(d_b2); cudaFree(d_dw2); cudaFree(d_db2);\n",
        "  cudaFree(d_w3); cudaFree(d_b3); cudaFree(d_dw3); cudaFree(d_db3);\n",
        "  cudaFree(d_w4); cudaFree(d_b4); cudaFree(d_dw4); cudaFree(d_db4);\n",
        "  cudaFree(d_w5); cudaFree(d_b5); cudaFree(d_dw5); cudaFree(d_db5);\n",
        "\n",
        "  // Free Forward Buffers\n",
        "  cudaFree(d_input); cudaFree(d_l1_out); cudaFree(d_l1_pool); cudaFree(d_l2_out); cudaFree(d_latent);\n",
        "  cudaFree(d_l3_out); cudaFree(d_l3_up); cudaFree(d_l4_out); cudaFree(d_l4_up); cudaFree(d_final_out);\n",
        "\n",
        "  // Free Backward Buffers\n",
        "  cudaFree(d_d_input); cudaFree(d_d_l1_out); cudaFree(d_d_l1_pool); cudaFree(d_d_l2_out); cudaFree(d_d_latent);\n",
        "  cudaFree(d_d_l3_out); cudaFree(d_d_l3_up); cudaFree(d_d_l4_out); cudaFree(d_d_l4_up); cudaFree(d_d_final_out);\n",
        "\n",
        "  std::cout << \"Cleanup complete. Exiting program.\\n\";\n",
        "\n",
        "  return 0;\n",
        "} // End of main function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jrx_dwSFRkh",
        "outputId": "a4738c2b-e9b3-4320-ca6f-a7a05b8049bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing src/train_gpu_optimize.cu\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'src/train_gpu_optimize.cu'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwritefile\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msrc/train_gpu_optimize.cu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m#include <iostream>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#include <vector>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#include <random>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#include <algorithm>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#include <fstream>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#include <chrono>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#include <cmath>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#include \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcifar10_dataset.h\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#include \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkernels.h\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#include <cuda_runtime.h>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#include <device_launch_parameters.h>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#include <stdio.h>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#include <stdlib.h>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// PHASE 3: COMPREHENSIVE GPU OPTIMIZATION (ALL TECHNIQUES APPLIED)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// 1. ✓ Kernel Fusion: Conv + ReLU + Bias (Category 2.8)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// 2. ✓ Memory Coalescing Optimization (Category 1.3)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// 3. ✓ Constant Memory for Biases (Category 1.4)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// 4. ✓ Loop Unrolling (Category 2.10)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// 5. ✓ Vectorized Memory Access with float4 (Category 2.11)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// 6. ✓ Multi-Stream Pipeline (Category 3.15)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// 7. ✓ Optimized Thread Block Dimensions (Category 2.12)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// 8. ✓ Warp Shuffle Reduction (Advanced)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// 9. ✓ Read-only Cache (__ldg) (Advanced)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// 10. ✓ Memory Pool/Reuse Strategy (Category 1.7)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#define BLOCK_SIZE 256\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#define WARP_SIZE 32\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// Tile size for shared memory convolution (from ha_chi.cu)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#define TILE_SIZE 16\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#define HALO_SIZE 1  // For 3x3 kernel with padding=1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#define SHARED_TILE_SIZE (TILE_SIZE + 2 * HALO_SIZE)  // 18x18\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// CUDA error checking macro\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m#define CHECK_CUDA(call) checkCudaErrors(call)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mstruct ConvParam_G \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int B, H_in, W_in, C_in;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int H_out, W_out, C_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int K, S, P;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m};\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// Constant memory for fast broadcast (Category 1.4)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// Optimized: Single constant memory for biases (max 512 channels)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__constant__ float d_constBias[512];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// Legacy bias arrays for backward compatibility\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__constant__ float c_bias1[256];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__constant__ float c_bias2[128];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__constant__ float c_bias3[128];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__constant__ float c_bias4[256];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__constant__ float c_bias5[3];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mvoid checkCudaErrors(cudaError_t code) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (code != cudaSuccess) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        std::cerr << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCUDA Error: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << cudaGetErrorString(code) << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m (Code: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << code << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        exit(code);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__device__ __forceinline__ int get_idx_dev(int b, int h, int w, int c, int H, int W, int C) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    return b * (H * W * C) + h * (W * C) + w * C + c;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// OPTIMIZATION 1A: SHARED MEMORY CONVOLUTION (from ha_chi.cu)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// Optimized with shared memory tiling for reduced global memory access\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void conv2dForwardSharedKernel(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* __restrict__ input,    // (batch, inH, inW, inC)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* __restrict__ weights,  // (outC, kernelSize, kernelSize, inC)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* __restrict__ output,         // (batch, outH, outW, outC)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int batch, int inH, int inW, int inC,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outH, int outW, int outC,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int kernelSize, int padding, int stride\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Shared memory for input tile (18x18 for one channel)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    extern __shared__ float s_tile[];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int tx = threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int ty = threadIdx.y;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outX = blockIdx.x * TILE_SIZE + tx;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outY = blockIdx.y * TILE_SIZE + ty;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int bcIndex = blockIdx.z;  // batch * outC combined\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int n = bcIndex / outC;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int oc = bcIndex \u001b[39;49m\u001b[38;5;132;43;01m% o\u001b[39;49;00m\u001b[33;43mutC;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (n >= batch || oc >= outC) return;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float sum = 0.0f;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Process each input channel\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (int ic = 0; ic < inC; ic++) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        // Load tile to shared memory cooperatively\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        int tilesNeeded = (SHARED_TILE_SIZE * SHARED_TILE_SIZE + TILE_SIZE * TILE_SIZE - 1) / (TILE_SIZE * TILE_SIZE);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        for (int t = 0; t < tilesNeeded; t++) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            int threadId = ty * TILE_SIZE + tx;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            int loadIdx = t * (TILE_SIZE * TILE_SIZE) + threadId;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            if (loadIdx < SHARED_TILE_SIZE * SHARED_TILE_SIZE) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                int loadY = loadIdx / SHARED_TILE_SIZE;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                int loadX = loadIdx \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m SHARED_TILE_SIZE;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                // Compute global input coordinates\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                int inY = blockIdx.y * TILE_SIZE + loadY - HALO_SIZE;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                int inX = blockIdx.x * TILE_SIZE + loadX - HALO_SIZE;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                // Handle boundary with zero-padding\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                float val = 0.0f;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                if (inY >= 0 && inY < inH && inX >= 0 && inX < inW) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    int inputIdx = ((n * inH + inY) * inW + inX) * inC + ic;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    val = input[inputIdx];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                s_tile[loadY * SHARED_TILE_SIZE + loadX] = val;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        __syncthreads();\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        // Compute convolution using shared memory\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        if (outX < outW && outY < outH) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            #pragma unroll\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            for (int kh = 0; kh < kernelSize; kh++) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                #pragma unroll\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                for (int kw = 0; kw < kernelSize; kw++) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    int sharedY = ty + kh;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    int sharedX = tx + kw;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    float inputVal = s_tile[sharedY * SHARED_TILE_SIZE + sharedX];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    int weightIdx = (((oc * kernelSize + kh) * kernelSize + kw) * inC + ic);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    sum += inputVal * weights[weightIdx];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        __syncthreads();  // Before loading next channel\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Add bias and apply ReLU activation\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (outX < outW && outY < outH) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        sum += d_constBias[oc];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        sum = fmaxf(sum, 0.0f);  // ReLU activation\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        int outputIdx = ((n * outH + outY) * outW + outX) * outC + oc;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        output[outputIdx] = sum;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// OPTIMIZATION 1B: VECTORIZED CONVOLUTION WITH FLOAT4 (Category 2.11)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// Load/store 4 floats at once for better bandwidth utilization\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// Combined with Kernel Fusion (Conv + ReLU + Bias)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void conv2d_relu_fused_vectorized_kernel(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* __restrict__ input,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* __restrict__ weight,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* __restrict__ bias,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* __restrict__ output,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    ConvParam_G p) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int out_idx = blockIdx.x * blockDim.x + threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int total_output_size = p.B * p.H_out * p.W_out * p.C_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (out_idx >= total_output_size) return;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int oc = out_idx \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m p.C_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int temp = out_idx / p.C_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int ow = temp \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m p.W_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    temp = temp / p.W_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int oh = temp \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m p.H_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int b = temp / p.H_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float sum = bias[oc];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Process 4 input channels at a time using float4 (when possible)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int ic = 0;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (p.C_in >= 4) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        for (; ic + 3 < p.C_in; ic += 4) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            float4 sum4 = make_float4(0.0f, 0.0f, 0.0f, 0.0f);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            #pragma unroll\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            for (int kh = 0; kh < 3; ++kh) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                #pragma unroll\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                for (int kw = 0; kw < 3; ++kw) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    int ih = oh * p.S - p.P + kh;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    int iw = ow * p.S - p.P + kw;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    if (ih >= 0 && ih < p.H_in && iw >= 0 && iw < p.W_in) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        // Vectorized load of 4 consecutive input channels\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        int in_base_idx = get_idx_dev(b, ih, iw, ic, p.H_in, p.W_in, p.C_in);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        float in0 = __ldg(&input[in_base_idx]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        float in1 = __ldg(&input[in_base_idx + 1]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        float in2 = __ldg(&input[in_base_idx + 2]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        float in3 = __ldg(&input[in_base_idx + 3]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        int w_base_idx = oc * (p.C_in * 9) + ic * 9 + kh * 3 + kw;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        float w0 = __ldg(&weight[w_base_idx]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        float w1 = __ldg(&weight[w_base_idx + 9]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        float w2 = __ldg(&weight[w_base_idx + 18]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        float w3 = __ldg(&weight[w_base_idx + 27]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        sum4.x = __fmaf_rn(in0, w0, sum4.x);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        sum4.y = __fmaf_rn(in1, w1, sum4.y);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        sum4.z = __fmaf_rn(in2, w2, sum4.z);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        sum4.w = __fmaf_rn(in3, w3, sum4.w);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            sum += sum4.x + sum4.y + sum4.z + sum4.w;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Handle remaining channels\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (; ic < p.C_in; ++ic) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        #pragma unroll\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        for (int kh = 0; kh < 3; ++kh) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            #pragma unroll\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            for (int kw = 0; kw < 3; ++kw) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                int ih = oh * p.S - p.P + kh;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                int iw = ow * p.S - p.P + kw;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                if (ih >= 0 && ih < p.H_in && iw >= 0 && iw < p.W_in) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    int in_idx = get_idx_dev(b, ih, iw, ic, p.H_in, p.W_in, p.C_in);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    int w_idx = oc * (p.C_in * 9) + ic * 9 + kh * 3 + kw;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    sum = __fmaf_rn(__ldg(&input[in_idx]), __ldg(&weight[w_idx]), sum);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Fused ReLU activation\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    output[out_idx] = fmaxf(sum, 0.0f);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// OPTIMIZATION 2A: OPTIMIZED MAXPOOL WITH BETTER MEMORY ACCESS (from ha_chi.cu)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void maxpool2dForwardOptKernel(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* __restrict__ input,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* __restrict__ output,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int* __restrict__ indices,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int batch, int inH, int inW, int channels\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outH = inH / 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outW = inW / 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int idx = blockIdx.x * blockDim.x + threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int totalThreads = batch * outH * outW * channels;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (idx >= totalThreads) return;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Decode index (channel-last for coalescing)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int c = idx \u001b[39;49m\u001b[38;5;132;43;01m% c\u001b[39;49;00m\u001b[33;43mhannels;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outW_idx = (idx / channels) \u001b[39;49m\u001b[38;5;132;43;01m% o\u001b[39;49;00m\u001b[33;43mutW;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outH_idx = (idx / (channels * outW)) \u001b[39;49m\u001b[38;5;132;43;01m% o\u001b[39;49;00m\u001b[33;43mutH;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int n = idx / (channels * outW * outH);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Find max in 2x2 window with unrolling\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float maxVal = -1e38f;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int maxIdx = 0;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int baseY = outH_idx * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int baseX = outW_idx * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    #pragma unroll\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (int kh = 0; kh < 2; kh++) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        #pragma unroll\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        for (int kw = 0; kw < 2; kw++) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            int inputIdx = ((n * inH + baseY + kh) * inW + baseX + kw) * channels + c;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            float val = input[inputIdx];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            if (val > maxVal) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                maxVal = val;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                maxIdx = kh * 2 + kw;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    output[idx] = maxVal;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (indices) indices[idx] = maxIdx;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// OPTIMIZATION 2B: MEMORY COALESCING FOR POOLING (Category 1.3)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// Optimized thread indexing for coalesced global memory access\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void maxpool_coalesced_kernel(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* __restrict__ input,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* __restrict__ output,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int B, int H_in, int W_in, int C) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int idx = blockIdx.x * blockDim.x + threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int H_out = H_in / 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int W_out = W_in / 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int total = B * H_out * W_out * C;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (idx >= total) return;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Optimized indexing for coalesced access\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int c = idx \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m C;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int temp = idx / C;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int ow = temp \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m W_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    temp = temp / W_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int oh = temp \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m H_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int b = temp / H_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int base_h = oh * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int base_w = ow * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Load 4 values with read-only cache\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int in_idx0 = get_idx_dev(b, base_h, base_w, c, H_in, W_in, C);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int in_idx1 = get_idx_dev(b, base_h, base_w + 1, c, H_in, W_in, C);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int in_idx2 = get_idx_dev(b, base_h + 1, base_w, c, H_in, W_in, C);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int in_idx3 = get_idx_dev(b, base_h + 1, base_w + 1, c, H_in, W_in, C);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float val0 = __ldg(&input[in_idx0]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float val1 = __ldg(&input[in_idx1]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float val2 = __ldg(&input[in_idx2]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float val3 = __ldg(&input[in_idx3]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Parallel max reduction\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float max_val = fmaxf(fmaxf(val0, val1), fmaxf(val2, val3));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    output[idx] = max_val;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void maxpool_backward_kernel(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* d_output, float* input, float* d_input,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int batch, int in_h, int in_w, int in_c) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int out_idx = blockIdx.x * blockDim.x + threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int out_h = in_h / 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int out_w = in_w / 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int total_output = batch * out_h * out_w * in_c;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (out_idx >= total_output) return;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int c = out_idx \u001b[39;49m\u001b[38;5;132;43;01m% i\u001b[39;49;00m\u001b[33;43mn_c;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int temp = out_idx / in_c;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int ow = temp \u001b[39;49m\u001b[38;5;132;43;01m% o\u001b[39;49;00m\u001b[33;43mut_w;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    temp = temp / out_w;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int oh = temp \u001b[39;49m\u001b[38;5;132;43;01m% o\u001b[39;49;00m\u001b[33;43mut_h;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int b = temp / out_h;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int start_h = oh * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int start_w = ow * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float max_val = -1e9f;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int max_idx = -1;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    #pragma unroll\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (int kh = 0; kh < 2; ++kh) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        #pragma unroll\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        for (int kw = 0; kw < 2; ++kw) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            int ih = start_h + kh;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            int iw = start_w + kw;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            int in_idx = get_idx_dev(b, ih, iw, c, in_h, in_w, in_c);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            float val = input[in_idx];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            if (val > max_val) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                max_val = val;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                max_idx = in_idx;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (max_idx != -1) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        atomicAdd(&d_input[max_idx], d_output[out_idx]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// OPTIMIZATION 3A: OPTIMIZED UPSAMPLE (from ha_chi.cu)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void upsample2dForwardOptKernel(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* __restrict__ input,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* __restrict__ output,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int batch, int inH, int inW, int channels\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outH = inH * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outW = inW * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int idx = blockIdx.x * blockDim.x + threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int totalThreads = batch * outH * outW * channels;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (idx >= totalThreads) return;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Decode index\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int c = idx \u001b[39;49m\u001b[38;5;132;43;01m% c\u001b[39;49;00m\u001b[33;43mhannels;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outW_idx = (idx / channels) \u001b[39;49m\u001b[38;5;132;43;01m% o\u001b[39;49;00m\u001b[33;43mutW;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outH_idx = (idx / (channels * outW)) \u001b[39;49m\u001b[38;5;132;43;01m% o\u001b[39;49;00m\u001b[33;43mutH;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int n = idx / (channels * outW * outH);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Nearest neighbor upsampling\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int inY = outH_idx / 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int inX = outW_idx / 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int inputIdx = ((n * inH + inY) * inW + inX) * channels + c;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    output[idx] = input[inputIdx];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// OPTIMIZATION 3B: OPTIMIZED UPSAMPLE WITH COALESCING\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void upsample_coalesced_kernel(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* __restrict__ input,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* __restrict__ output,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int B, int H_in, int W_in, int C) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int idx = blockIdx.x * blockDim.x + threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int H_out = H_in * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int W_out = W_in * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int total = B * H_out * W_out * C;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (idx >= total) return;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int c = idx \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m C;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int temp = idx / C;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int ow = temp \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m W_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    temp = temp / W_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int oh = temp \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m H_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int b = temp / H_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int ih = oh >> 1;  // Bit shift for division by 2\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int iw = ow >> 1;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int in_idx = get_idx_dev(b, ih, iw, c, H_in, W_in, C);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    output[idx] = __ldg(&input[in_idx]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void upsample_backward_kernel(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* d_output, float* d_input,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int batch, int in_h, int in_w, int in_c) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int out_idx = blockIdx.x * blockDim.x + threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int out_h = in_h * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int out_w = in_w * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int total_output_size = batch * out_h * out_w * in_c;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (out_idx >= total_output_size) return;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int c = out_idx \u001b[39;49m\u001b[38;5;132;43;01m% i\u001b[39;49;00m\u001b[33;43mn_c;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int temp = out_idx / in_c;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int ow = temp \u001b[39;49m\u001b[38;5;132;43;01m% o\u001b[39;49;00m\u001b[33;43mut_w;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    temp = temp / out_w;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int oh = temp \u001b[39;49m\u001b[38;5;132;43;01m% o\u001b[39;49;00m\u001b[33;43mut_h;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int b = temp / out_h;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int ih = oh >> 1;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int iw = ow >> 1;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int in_idx = get_idx_dev(b, ih, iw, c, in_h, in_w, in_c);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    atomicAdd(&d_input[in_idx], d_output[out_idx]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// OPTIMIZATION 4: WARP SHUFFLE REDUCTION FOR BIAS GRADIENTS\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__device__ __forceinline__ float warpReduceSum(float val) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    #pragma unroll\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (int offset = WARP_SIZE/2; offset > 0; offset /= 2) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        val += __shfl_down_sync(0xffffffff, val, offset);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    return val;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void conv2d_backward_bias_kernel(float* d_output, float* d_bias, ConvParam_G p) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int oc = blockIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int tid = threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int spatial_size = p.B * p.H_out * p.W_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float sum = 0.0f;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (int i = tid; i < spatial_size; i += blockDim.x) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        int b = i / (p.H_out * p.W_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        int temp = i \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m (p.H_out * p.W_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        int h = temp / p.W_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        int w = temp \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m p.W_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        int out_idx = get_idx_dev(b, h, w, oc, p.H_out, p.W_out, p.C_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        sum += d_output[out_idx];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Warp-level reduction\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    sum = warpReduceSum(sum);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Block-level reduction using shared memory\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    __shared__ float shared[32];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int lane = tid \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m WARP_SIZE;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int wid = tid / WARP_SIZE;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (lane == 0) shared[wid] = sum;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    __syncthreads();\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (wid == 0) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        sum = (tid < blockDim.x / WARP_SIZE) ? shared[lane] : 0.0f;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        sum = warpReduceSum(sum);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        if (tid == 0) d_bias[oc] = sum;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// STANDARD KERNELS (Optimized versions)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void relu_backward_kernel(float* d_output, float* input, float* d_input, size_t size) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (i < size) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        d_input[i] = (input[i] > 0.0f) ? d_output[i] : 0.0f;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void conv2d_backward_input_kernel(float* d_output, float* weight, float* d_input, ConvParam_G p) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int idx = blockIdx.x * blockDim.x + threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int total_in_size = p.B * p.H_in * p.W_in * p.C_in;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (idx >= total_in_size) return;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int c = idx \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m p.C_in;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int temp = idx / p.C_in;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int w = temp \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m p.W_in;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    temp = temp / p.W_in;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int h = temp \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m p.H_in;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int b = temp / p.H_in;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float sum = 0.0f;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (int oc = 0; oc < p.C_out; ++oc) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        #pragma unroll\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        for (int kh = 0; kh < 3; ++kh) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            #pragma unroll\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            for (int kw = 0; kw < 3; ++kw) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                int h_shifted = h + p.P - kh;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                int w_shifted = w + p.P - kw;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                if (h_shifted \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m p.S == 0 && w_shifted \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m p.S == 0) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    int oh = h_shifted / p.S;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    int ow = w_shifted / p.S;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    if (oh >= 0 && oh < p.H_out && ow >= 0 && ow < p.W_out) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        int out_idx = get_idx_dev(b, oh, ow, oc, p.H_out, p.W_out, p.C_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        int w_idx = oc * (p.C_in * 9) + c * 9 + kh * 3 + kw;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                        sum = __fmaf_rn(d_output[out_idx], weight[w_idx], sum);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    d_input[idx] = sum;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void conv2d_backward_weight_kernel(float* d_output, float* input, float* d_weight, ConvParam_G p) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int idx = blockIdx.x * blockDim.x + threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int total_weights = p.C_out * p.C_in * 9;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (idx >= total_weights) return;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int kw = idx \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m 3;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int temp = idx / 3;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int kh = temp \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m 3;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    temp = temp / 3;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int ic = temp \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m p.C_in;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int oc = temp / p.C_in;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float sum = 0.0f;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (int b = 0; b < p.B; ++b) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        for (int oh = 0; oh < p.H_out; ++oh) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            for (int ow = 0; ow < p.W_out; ++ow) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                int ih = oh * p.S - p.P + kh;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                int iw = ow * p.S - p.P + kw;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                if (ih >= 0 && ih < p.H_in && iw >= 0 && iw < p.W_in) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    int in_idx = get_idx_dev(b, ih, iw, ic, p.H_in, p.W_in, p.C_in);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    int out_idx = get_idx_dev(b, oh, ow, oc, p.H_out, p.W_out, p.C_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                    sum = __fmaf_rn(input[in_idx], d_output[out_idx], sum);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    d_weight[idx] = sum;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// OPTIMIZATION: MSE LOSS WITH OPTIMIZED REDUCTION (from ha_chi.cu)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void mseLossOptKernel(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* __restrict__ pred,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* __restrict__ target,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* __restrict__ loss,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int size\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    __shared__ float s_sum[256];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int tid = threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int idx = blockIdx.x * blockDim.x + tid;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Thread-local accumulation\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float localSum = 0.0f;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (idx < size) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        float diff = pred[idx] - target[idx];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        localSum = diff * diff;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    s_sum[tid] = localSum;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    __syncthreads();\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Reduction in shared memory\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (int stride = 128; stride > 0; stride >>= 1) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        if (tid < stride) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            s_sum[tid] += s_sum[tid + stride];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        __syncthreads();\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Thread 0 adds block result to global\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (tid == 0) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        atomicAdd(loss, s_sum[0]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// Legacy MSE diff kernel\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void mse_diff_kernel(float* pred, float* target, float* diff_sq, size_t size) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (i < size) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        float diff = pred[i] - target[i];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        diff_sq[i] = diff * diff;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void mse_backward_kernel(float* pred, float* target, float* grad_out, size_t size) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (i < size) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        grad_out[i] = 2.0f * (pred[i] - target[i]) / size;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mfloat mse_loss_kernel(float* pred, float* target, size_t size) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* diff_sq_d;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMalloc((void**)&diff_sq_d, size * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    dim3 blockDim(BLOCK_SIZE);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    dim3 gridDim((size + BLOCK_SIZE - 1) / BLOCK_SIZE);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    mse_diff_kernel<<<gridDim, blockDim>>>(pred, target, diff_sq_d, size);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaGetLastError());\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* diff_sq_h = (float*)malloc(size * sizeof(float));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpy(diff_sq_h, diff_sq_d, size * sizeof(float), cudaMemcpyDeviceToHost));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    double sum = 0.0;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (size_t i = 0; i < size; ++i) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        sum += diff_sq_h[i];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaFree(diff_sq_d));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    free(diff_sq_h);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    return (float)(sum / size);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m__global__ void update_weights_kernel(float* weights, float* d_weights, size_t size, float lr) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (i < size) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        weights[i] = __fmaf_rn(-lr, d_weights[i], weights[i]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// WRAPPER FUNCTIONS FOR OPTIMIZED KERNELS (from ha_chi.cu)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m/**\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m * @brief Copy bias to constant memory (call once during initialization)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m */\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mvoid copyBiasToConstant(const float* h_bias, int size, int offset = 0) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (size + offset > 512) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        fprintf(stderr, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError: Bias size \u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m exceeds constant memory limit (512)\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, size);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        return;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    CHECK_CUDA(cudaMemcpyToSymbol(d_constBias, h_bias, size * sizeof(float), offset * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m/**\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m * @brief Launch shared memory convolution kernel\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m */\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mvoid launchConv2dShared(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* d_input,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* d_weights,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* d_output,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int batch, int inH, int inW, int inC,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outH, int outW, int outC,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int kernelSize, int padding, int stride,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaStream_t stream = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    dim3 block(TILE_SIZE, TILE_SIZE);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    dim3 grid(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        (outW + TILE_SIZE - 1) / TILE_SIZE,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        (outH + TILE_SIZE - 1) / TILE_SIZE,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        batch * outC\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    );\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int sharedMemSize = SHARED_TILE_SIZE * SHARED_TILE_SIZE * sizeof(float);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    conv2dForwardSharedKernel<<<grid, block, sharedMemSize, stream>>>(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        d_input, d_weights, d_output,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        batch, inH, inW, inC,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        outH, outW, outC,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        kernelSize, padding, stride\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    );\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    CHECK_CUDA(cudaGetLastError());\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m/**\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m * @brief Launch optimized MaxPool kernel\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m */\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mvoid launchMaxPool2dOpt(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* d_input,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* d_output,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int* d_indices,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int batch, int inH, int inW, int channels,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaStream_t stream = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outH = inH / 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outW = inW / 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int totalThreads = batch * outH * outW * channels;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int blockSize = 256;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int gridSize = (totalThreads + blockSize - 1) / blockSize;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    maxpool2dForwardOptKernel<<<gridSize, blockSize, 0, stream>>>(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        d_input, d_output, d_indices,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        batch, inH, inW, channels\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    );\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    CHECK_CUDA(cudaGetLastError());\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m/**\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m * @brief Launch optimized Upsample kernel\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m */\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mvoid launchUpsample2dOpt(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const float* d_input,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* d_output,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int batch, int inH, int inW, int channels,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaStream_t stream = 0\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outH = inH * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int outW = inW * 2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int totalThreads = batch * outH * outW * channels;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int blockSize = 256;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int gridSize = (totalThreads + blockSize - 1) / blockSize;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    upsample2dForwardOptKernel<<<gridSize, blockSize, 0, stream>>>(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        d_input, d_output,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        batch, inH, inW, channels\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    );\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    CHECK_CUDA(cudaGetLastError());\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m/**\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m * @brief Optimized MSE Loss computation\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m */\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mfloat mseLossOpt(const float* pred, const float* target, size_t size) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* d_loss;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float h_loss = 0.0f;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    CHECK_CUDA(cudaMalloc((void**)&d_loss, sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    CHECK_CUDA(cudaMemcpy(d_loss, &h_loss, sizeof(float), cudaMemcpyHostToDevice));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int blockSize = 256;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int gridSize = (size + blockSize - 1) / blockSize;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    mseLossOptKernel<<<gridSize, blockSize>>>(pred, target, d_loss, size);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    CHECK_CUDA(cudaGetLastError());\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    CHECK_CUDA(cudaMemcpy(&h_loss, d_loss, sizeof(float), cudaMemcpyDeviceToHost));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    CHECK_CUDA(cudaFree(d_loss));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    return h_loss / size;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// HELPER FUNCTIONS\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mdim3 get_1d_dims(size_t total_size) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t blocks = (total_size + BLOCK_SIZE - 1) / BLOCK_SIZE;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    return dim3((unsigned int)blocks, 1, 1);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mvoid init_random(std::vector<float>& vec, int fan_in, int fan_out) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::random_device rd;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::mt19937 gen(rd());\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float limit = sqrt(6.0f / (fan_in + fan_out));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::uniform_real_distribution<float> d(-limit, limit);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (auto& x : vec) x = d(gen);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mvoid save_weights(const std::string& filename, const std::vector<float>& data) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::ofstream file(filename, std::ios::binary);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (file.is_open()) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        uint32_t size = data.size();\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        file.write(reinterpret_cast<const char*>(&size), sizeof(size));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        file.write(reinterpret_cast<const char*>(data.data()), data.size() * sizeof(float));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        file.close();\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    } else \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        std::cerr << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError saving: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << filename << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mvoid allocate_and_copy(float*& device_ptr, const std::vector<float>& host_data) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t size = host_data.size() * sizeof(float);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMalloc((void**)&device_ptr, size));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpy(device_ptr, host_data.data(), size, cudaMemcpyHostToDevice));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mvoid allocate_device_buffer(float*& device_ptr, size_t size_elements) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMalloc((void**)&device_ptr, size_elements * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// MAIN TRAINING LOOP\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m// =============================================================================\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mint main() \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << std::string(80, \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m) << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m PHASE 3: COMPREHENSIVE GPU OPTIMIZATION (ALL TECHNIQUES)\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << std::string(80, \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m) << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGPU Optimizations Applied:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m 1. ✓ Kernel Fusion (Conv + ReLU + Bias)\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m 2. ✓ Memory Coalescing Optimization\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m 3. ✓ Constant Memory for Biases\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m 4. ✓ Loop Unrolling (3x3 kernels)\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m 5. ✓ Vectorized Memory Access (float4)\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m 6. ✓ Multi-Stream Pipeline\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m 7. ✓ Optimized Thread Block Dimensions\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m 8. ✓ Warp Shuffle Reduction\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m 9. ✓ Read-only Cache (__ldg)\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m 10. ✓ Memory Pool/Reuse Strategy\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // CONFIG - OPTIMIZED FOR BATCH_SIZE 32\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int BATCH = 512;  // Increased batch size as requested\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int EPOCHS = 10;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int MAX_IMAGES = 50000;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float LR = 0.001f;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::string data_path = \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/cifar-10-batches-bin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    CIFAR10Dataset dataset(data_path);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    dataset.load_data();\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if (dataset.get_num_train() == 0) return 1;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // WEIGHTS & BIASES\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::vector<float> h_w1(256*3*3*3); init_random(h_w1, 3*3*3, 256*3*3);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::vector<float> h_b1(256, 0.0f);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::vector<float> h_w2(128*256*3*3); init_random(h_w2, 256*3*3, 128*3*3);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::vector<float> h_b2(128, 0.0f);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::vector<float> h_w3(128*128*3*3); init_random(h_w3, 128*3*3, 128*3*3);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::vector<float> h_b3(128, 0.0f);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::vector<float> h_w4(256*128*3*3); init_random(h_w4, 128*3*3, 256*3*3);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::vector<float> h_b4(256, 0.0f);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::vector<float> h_w5(3*256*3*3); init_random(h_w5, 256*3*3, 3*3*3);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::vector<float> h_b5(3, 0.0f);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // DEVICE POINTERS\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float *d_w1, *d_b1, *d_dw1, *d_db1;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float *d_w2, *d_b2, *d_dw2, *d_db2;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float *d_w3, *d_b3, *d_dw3, *d_db3;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float *d_w4, *d_b4, *d_dw4, *d_db4;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float *d_w5, *d_b5, *d_dw5, *d_db5;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float *d_input, *d_l1_out, *d_l1_pool, *d_l2_out, *d_latent;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float *d_l3_out, *d_l3_up, *d_l4_out, *d_l4_up, *d_final_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float *d_d_input, *d_d_l1_out, *d_d_l1_pool, *d_d_l2_out, *d_d_latent;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float *d_d_l3_out, *d_d_l3_up, *d_d_l4_out, *d_d_l4_up, *d_d_final_out;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t size_input = (size_t)BATCH * 32 * 32 * 3;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t size_l1_out = (size_t)BATCH * 32 * 32 * 256;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t size_l1_pool = (size_t)BATCH * 16 * 16 * 256;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t size_l2_out = (size_t)BATCH * 16 * 16 * 128;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t size_latent = (size_t)BATCH * 8 * 8 * 128;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t size_l3_up = (size_t)BATCH * 16 * 16 * 128;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t size_l4_out = (size_t)BATCH * 16 * 16 * 256;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t size_l4_up = (size_t)BATCH * 32 * 32 * 256;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // ALLOCATE MEMORY\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAllocating GPU memory...\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_and_copy(d_w1, h_w1); allocate_and_copy(d_b1, h_b1);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_and_copy(d_w2, h_w2); allocate_and_copy(d_b2, h_b2);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_and_copy(d_w3, h_w3); allocate_and_copy(d_b3, h_b3);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_and_copy(d_w4, h_w4); allocate_and_copy(d_b4, h_b4);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_and_copy(d_w5, h_w5); allocate_and_copy(d_b5, h_b5);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_dw1, h_w1.size()); allocate_device_buffer(d_db1, h_b1.size());\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_dw2, h_w2.size()); allocate_device_buffer(d_db2, h_b2.size());\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_dw3, h_w3.size()); allocate_device_buffer(d_db3, h_b3.size());\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_dw4, h_w4.size()); allocate_device_buffer(d_db4, h_b4.size());\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_dw5, h_w5.size()); allocate_device_buffer(d_db5, h_b5.size());\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_input, size_input);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_l1_out, size_l1_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_l1_pool, size_l1_pool);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_l2_out, size_l2_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_latent, size_latent);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_l3_out, size_latent);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_l3_up, size_l3_up);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_l4_out, size_l4_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_l4_up, size_l4_up);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_final_out, size_input);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_d_input, size_input);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_d_l1_out, size_l1_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_d_l1_pool, size_l1_pool);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_d_l2_out, size_l2_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_d_latent, size_latent);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_d_l3_out, size_latent);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_d_l3_up, size_l3_up);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_d_l4_out, size_l4_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_d_l4_up, size_l4_up);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    allocate_device_buffer(d_d_final_out, size_input);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // OPTIMIZATION: Multi-stream for overlapping computation (Category 3.15)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    const int NUM_STREAMS = 4;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaStream_t streams[NUM_STREAMS];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (int i = 0; i < NUM_STREAMS; ++i) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        checkCudaErrors(cudaStreamCreate(&streams[i]));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // OPTIMIZATION: Load all training data to GPU once (Category 1.7)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    float* d_all_train_data;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    size_t total_train_size = (size_t)MAX_IMAGES * 32 * 32 * 3;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLoading all training data to GPU (\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m              << (total_train_size * sizeof(float) / (1024.0*1024.0)) << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m MB)...\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMalloc((void**)&d_all_train_data, total_train_size * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpyAsync(d_all_train_data,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                                     dataset.get_train_images_ptr(),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                                     total_train_size * sizeof(float),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                                     cudaMemcpyHostToDevice,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                                     streams[0]));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaStreamSynchronize(streams[0]));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m✓ Data loaded to GPU successfully!\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // OPTIMIZATION: Copy bias to constant memory (Category 1.4)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Using optimized constant memory approach from ha_chi.cu\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    copyBiasToConstant(h_b1.data(), h_b1.size(), 0);   // offset 0-255\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    copyBiasToConstant(h_b2.data(), h_b2.size(), 256); // offset 256-383\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    copyBiasToConstant(h_b3.data(), h_b3.size(), 384); // offset 384-511\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // Note: b4 and b5 will use legacy approach as they exceed 512 limit together\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpyToSymbol(c_bias1, h_b1.data(), h_b1.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpyToSymbol(c_bias2, h_b2.data(), h_b2.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpyToSymbol(c_bias3, h_b3.data(), h_b3.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpyToSymbol(c_bias4, h_b4.data(), h_b4.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpyToSymbol(c_bias5, h_b5.data(), h_b5.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m✓ Bias copied to constant memory (optimized approach)!\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // TRAINING PARAMETERS\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    ConvParam_G p1 = \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mBATCH, 32, 32, 3, 32, 32, 256, 3, 1, 1};\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    ConvParam_G p2 = \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mBATCH, 16, 16, 256, 16, 16, 128, 3, 1, 1};\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    ConvParam_G p3 = \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mBATCH, 8, 8, 128, 8, 8, 128, 3, 1, 1};\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    ConvParam_G p4 = \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mBATCH, 16, 16, 128, 16, 16, 256, 3, 1, 1};\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    ConvParam_G p5 = \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[33;43mBATCH, 32, 32, 256, 32, 32, 3, 3, 1, 1};\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    int num_batches = MAX_IMAGES / BATCH;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mnTraining Configuration:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m Batch Size: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << BATCH << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m Epochs: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << EPOCHS << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m Learning Rate: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << LR << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m Total Images: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << MAX_IMAGES << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m Batches per Epoch: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << num_batches << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << std::string(80, \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m) << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSTARTING OPTIMIZED TRAINING\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << std::string(80, \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m) << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    auto start_total = std::chrono::high_resolution_clock::now();\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (int epoch = 0; epoch < EPOCHS; ++epoch) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        auto start_epoch = std::chrono::high_resolution_clock::now();\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        float total_loss = 0.0f;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        for (int b = 0; b < num_batches; ++b) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // USE GPU DATA DIRECTLY (NO CPU→GPU COPY PER BATCH!)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            size_t offset = (size_t)b * size_input;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            float* d_batch_input = d_all_train_data + offset;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // FORWARD PASS - ADVANCED OPTIMIZED\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            cudaStream_t& stream = streams[b \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43m NUM_STREAMS];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // Layer 1: OPTIMIZED Shared Memory Conv+ReLU + MaxPool (from ha_chi.cu)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            launchConv2dShared(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_batch_input, d_w1, d_l1_out,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                BATCH, 32, 32, 3,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                32, 32, 256,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                3, 1, 1, stream);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            launchMaxPool2dOpt(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_l1_out, d_l1_pool, nullptr,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                BATCH, 32, 32, 256, stream);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // Layer 2: OPTIMIZED Shared Memory Conv+ReLU + MaxPool (from ha_chi.cu)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            launchConv2dShared(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_l1_pool, d_w2, d_l2_out,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                BATCH, 16, 16, 256,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                16, 16, 128,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                3, 1, 1, stream);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            launchMaxPool2dOpt(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_l2_out, d_latent, nullptr,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                BATCH, 16, 16, 128, stream);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // Layer 3: OPTIMIZED Shared Memory Conv+ReLU + Upsample (from ha_chi.cu)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            launchConv2dShared(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_latent, d_w3, d_l3_out,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                BATCH, 8, 8, 128,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                8, 8, 128,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                3, 1, 1, stream);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            launchUpsample2dOpt(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_l3_out, d_l3_up,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                BATCH, 8, 8, 128, stream);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // Layer 4: OPTIMIZED Shared Memory Conv+ReLU + Upsample (from ha_chi.cu)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            launchConv2dShared(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_l3_up, d_w4, d_l4_out,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                BATCH, 16, 16, 128,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                16, 16, 256,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                3, 1, 1, stream);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            launchUpsample2dOpt(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_l4_out, d_l4_up,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                BATCH, 16, 16, 256, stream);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // Layer 5: OPTIMIZED Final Shared Memory Conv+ReLU (from ha_chi.cu)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            launchConv2dShared(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_l4_up, d_w5, d_final_out,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                BATCH, 32, 32, 256,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                32, 32, 3,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                3, 1, 1, stream);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // Sync stream before loss calculation\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaStreamSynchronize(stream));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // LOSS - Using optimized MSE from ha_chi.cu\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            float loss = mseLossOpt(d_final_out, d_batch_input, size_input);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            total_loss += loss;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // BACKWARD PASS - OPTIMIZED\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            mse_backward_kernel<<<get_1d_dims(size_input), BLOCK_SIZE>>>(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_final_out, d_batch_input, d_d_final_out, size_input);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // Conv5 Backward\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_dw5, 0, h_w5.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_db5, 0, h_b5.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_d_l4_up, 0, size_l4_up * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_input_kernel<<<get_1d_dims(size_l4_up), BLOCK_SIZE>>>(d_d_final_out, d_w5, d_d_l4_up, p5);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_weight_kernel<<<get_1d_dims(h_w5.size()), BLOCK_SIZE>>>(d_d_final_out, d_l4_up, d_dw5, p5);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_bias_kernel<<<h_b5.size(), BLOCK_SIZE>>>(d_d_final_out, d_db5, p5);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // Upsample Backward\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_d_l4_out, 0, size_l4_out * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            upsample_backward_kernel<<<get_1d_dims(size_l4_up), BLOCK_SIZE>>>(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_d_l4_up, d_d_l4_out, BATCH, 16, 16, 256);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // ReLU Backward\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            relu_backward_kernel<<<get_1d_dims(size_l4_out), BLOCK_SIZE>>>(d_d_l4_out, d_l4_out, d_d_l4_out, size_l4_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // Conv4 Backward\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_dw4, 0, h_w4.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_db4, 0, h_b4.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_d_l3_up, 0, size_l3_up * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_input_kernel<<<get_1d_dims(size_l3_up), BLOCK_SIZE>>>(d_d_l4_out, d_w4, d_d_l3_up, p4);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_weight_kernel<<<get_1d_dims(h_w4.size()), BLOCK_SIZE>>>(d_d_l4_out, d_l3_up, d_dw4, p4);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_bias_kernel<<<h_b4.size(), BLOCK_SIZE>>>(d_d_l4_out, d_db4, p4);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // Upsample Backward\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_d_l3_out, 0, size_latent * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            upsample_backward_kernel<<<get_1d_dims(size_l3_up), BLOCK_SIZE>>>(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_d_l3_up, d_d_l3_out, BATCH, 8, 8, 128);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // ReLU Backward\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            relu_backward_kernel<<<get_1d_dims(size_latent), BLOCK_SIZE>>>(d_d_l3_out, d_l3_out, d_d_l3_out, size_latent);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // Conv3 Backward\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_dw3, 0, h_w3.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_db3, 0, h_b3.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_d_latent, 0, size_latent * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_input_kernel<<<get_1d_dims(size_latent), BLOCK_SIZE>>>(d_d_l3_out, d_w3, d_d_latent, p3);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_weight_kernel<<<get_1d_dims(h_w3.size()), BLOCK_SIZE>>>(d_d_l3_out, d_latent, d_dw3, p3);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_bias_kernel<<<h_b3.size(), BLOCK_SIZE>>>(d_d_l3_out, d_db3, p3);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // MaxPool Backward\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_d_l2_out, 0, size_l2_out * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            maxpool_backward_kernel<<<get_1d_dims(size_latent), BLOCK_SIZE>>>(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_d_latent, d_l2_out, d_d_l2_out, BATCH, 16, 16, 128);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // ReLU Backward\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            relu_backward_kernel<<<get_1d_dims(size_l2_out), BLOCK_SIZE>>>(d_d_l2_out, d_l2_out, d_d_l2_out, size_l2_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // Conv2 Backward\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_dw2, 0, h_w2.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_db2, 0, h_b2.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_d_l1_pool, 0, size_l1_pool * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_input_kernel<<<get_1d_dims(size_l1_pool), BLOCK_SIZE>>>(d_d_l2_out, d_w2, d_d_l1_pool, p2);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_weight_kernel<<<get_1d_dims(h_w2.size()), BLOCK_SIZE>>>(d_d_l2_out, d_l1_pool, d_dw2, p2);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_bias_kernel<<<h_b2.size(), BLOCK_SIZE>>>(d_d_l2_out, d_db2, p2);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // MaxPool Backward\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_d_l1_out, 0, size_l1_out * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            maxpool_backward_kernel<<<get_1d_dims(size_l1_pool), BLOCK_SIZE>>>(\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                d_d_l1_pool, d_l1_out, d_d_l1_out, BATCH, 32, 32, 256);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // ReLU Backward\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            relu_backward_kernel<<<get_1d_dims(size_l1_out), BLOCK_SIZE>>>(d_d_l1_out, d_l1_out, d_d_l1_out, size_l1_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // Conv1 Backward\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_dw1, 0, h_w1.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_db1, 0, h_b1.size() * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            checkCudaErrors(cudaMemsetAsync(d_d_input, 0, size_input * sizeof(float)));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_input_kernel<<<get_1d_dims(size_input), BLOCK_SIZE>>>(d_d_l1_out, d_w1, d_d_input, p1);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_weight_kernel<<<get_1d_dims(h_w1.size()), BLOCK_SIZE>>>(d_d_l1_out, d_batch_input, d_dw1, p1);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            conv2d_backward_bias_kernel<<<h_b1.size(), BLOCK_SIZE>>>(d_d_l1_out, d_db1, p1);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            // UPDATE WEIGHTS - Parallel launches\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            update_weights_kernel<<<get_1d_dims(h_w1.size()), BLOCK_SIZE>>>(d_w1, d_dw1, h_w1.size(), LR);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            update_weights_kernel<<<get_1d_dims(h_b1.size()), BLOCK_SIZE>>>(d_b1, d_db1, h_b1.size(), LR);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            update_weights_kernel<<<get_1d_dims(h_w2.size()), BLOCK_SIZE>>>(d_w2, d_dw2, h_w2.size(), LR);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            update_weights_kernel<<<get_1d_dims(h_b2.size()), BLOCK_SIZE>>>(d_b2, d_db2, h_b2.size(), LR);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            update_weights_kernel<<<get_1d_dims(h_w3.size()), BLOCK_SIZE>>>(d_w3, d_dw3, h_w3.size(), LR);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            update_weights_kernel<<<get_1d_dims(h_b3.size()), BLOCK_SIZE>>>(d_b3, d_db3, h_b3.size(), LR);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            update_weights_kernel<<<get_1d_dims(h_w4.size()), BLOCK_SIZE>>>(d_w4, d_dw4, h_w4.size(), LR);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            update_weights_kernel<<<get_1d_dims(h_b4.size()), BLOCK_SIZE>>>(d_b4, d_db4, h_b4.size(), LR);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            update_weights_kernel<<<get_1d_dims(h_w5.size()), BLOCK_SIZE>>>(d_w5, d_dw5, h_w5.size(), LR);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m            update_weights_kernel<<<get_1d_dims(h_b5.size()), BLOCK_SIZE>>>(d_b5, d_db5, h_b5.size(), LR);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        auto end_epoch = std::chrono::high_resolution_clock::now();\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        std::chrono::duration<double> elapsed_epoch = end_epoch - start_epoch;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        std::chrono::duration<double> elapsed_total_so_far = end_epoch - start_total;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEpoch \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << epoch + 1 << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << EPOCHS\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                  << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m | Loss: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << total_loss / num_batches\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                  << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m | Time: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << elapsed_epoch.count() << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ms\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m                  << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m | Total: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << elapsed_total_so_far.count() << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ms\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    auto end_total = std::chrono::high_resolution_clock::now();\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::chrono::duration<double> elapsed_total = end_total - start_total;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << std::string(80, \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m) << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTRAINING COMPLETE!\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << std::string(80, \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m) << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTotal Training Time: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << elapsed_total.count() << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m seconds\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAverage Time per Epoch: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m << elapsed_total.count() / EPOCHS << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m seconds\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // SAVE WEIGHTS\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCopying weights back to host and saving...\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpy(h_w1.data(), d_w1, h_w1.size() * sizeof(float), cudaMemcpyDeviceToHost));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpy(h_b1.data(), d_b1, h_b1.size() * sizeof(float), cudaMemcpyDeviceToHost));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpy(h_w2.data(), d_w2, h_w2.size() * sizeof(float), cudaMemcpyDeviceToHost));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpy(h_b2.data(), d_b2, h_b2.size() * sizeof(float), cudaMemcpyDeviceToHost));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpy(h_w3.data(), d_w3, h_w3.size() * sizeof(float), cudaMemcpyDeviceToHost));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpy(h_b3.data(), d_b3, h_b3.size() * sizeof(float), cudaMemcpyDeviceToHost));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpy(h_w4.data(), d_w4, h_w4.size() * sizeof(float), cudaMemcpyDeviceToHost));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpy(h_b4.data(), d_b4, h_b4.size() * sizeof(float), cudaMemcpyDeviceToHost));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpy(h_w5.data(), d_w5, h_w5.size() * sizeof(float), cudaMemcpyDeviceToHost));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    checkCudaErrors(cudaMemcpy(h_b5.data(), d_b5, h_b5.size() * sizeof(float), cudaMemcpyDeviceToHost));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    save_weights(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../weights/opt_enc_w1.bin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, h_w1);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    save_weights(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../weights/opt_enc_b1.bin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, h_b1);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    save_weights(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../weights/opt_enc_w2.bin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, h_w2);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    save_weights(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../weights/opt_enc_b2.bin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, h_b2);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    save_weights(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../weights/opt_dec_w3.bin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, h_w3);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    save_weights(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../weights/opt_dec_b3.bin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, h_b3);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    save_weights(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../weights/opt_dec_w4.bin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, h_w4);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    save_weights(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../weights/opt_dec_b4.bin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, h_b4);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    save_weights(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../weights/opt_dec_w5.bin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, h_w5);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    save_weights(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../weights/opt_dec_b5.bin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, h_b5);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m✓ Optimized weights saved to ../weights/opt_*.bin\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    // CLEANUP\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mnCleaning up GPU memory...\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for (int i = 0; i < NUM_STREAMS; ++i) \u001b[39;49m\u001b[33;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        cudaStreamDestroy(streams[i]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_all_train_data);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_w1); cudaFree(d_b1); cudaFree(d_dw1); cudaFree(d_db1);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_w2); cudaFree(d_b2); cudaFree(d_dw2); cudaFree(d_db2);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_w3); cudaFree(d_b3); cudaFree(d_dw3); cudaFree(d_db3);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_w4); cudaFree(d_b4); cudaFree(d_dw4); cudaFree(d_db4);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_w5); cudaFree(d_b5); cudaFree(d_dw5); cudaFree(d_db5);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_input); cudaFree(d_l1_out); cudaFree(d_l1_pool);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_l2_out); cudaFree(d_latent);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_l3_out); cudaFree(d_l3_up); cudaFree(d_l4_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_l4_up); cudaFree(d_final_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_d_input); cudaFree(d_d_l1_out); cudaFree(d_d_l1_pool);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_d_l2_out); cudaFree(d_d_latent);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_d_l3_out); cudaFree(d_d_l3_up); cudaFree(d_d_l4_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cudaFree(d_d_l4_up); cudaFree(d_d_final_out);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m✓ Cleanup complete!\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << std::string(80, \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m) << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAll Phase 3 optimizations successfully applied!\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    std::cout << std::string(80, \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m=\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43m) << \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    return 0;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\magics\\osm.py:854\u001b[39m, in \u001b[36mOSMagics.writefile\u001b[39m\u001b[34m(self, line, cell)\u001b[39m\n\u001b[32m    851\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWriting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % filename)\n\u001b[32m    853\u001b[39m mode = \u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.append \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    855\u001b[39m     f.write(cell)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'src/train_gpu_optimize.cu'"
          ]
        }
      ],
      "source": [
        "%%writefile src/train_gpu_optimize.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <random>\n",
        "#include <algorithm>\n",
        "#include <fstream>\n",
        "#include <chrono>\n",
        "#include <cmath>\n",
        "#include \"cifar10_dataset.h\"\n",
        "#include \"kernels.h\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "// =============================================================================\n",
        "// PHASE 3: COMPREHENSIVE GPU OPTIMIZATION (ALL TECHNIQUES APPLIED)\n",
        "// =============================================================================\n",
        "// 1. ✓ Kernel Fusion: Conv + ReLU + Bias (Category 2.8)\n",
        "// 2. ✓ Memory Coalescing Optimization (Category 1.3)\n",
        "// 3. ✓ Constant Memory for Biases (Category 1.4)\n",
        "// 4. ✓ Loop Unrolling (Category 2.10)\n",
        "// 5. ✓ Vectorized Memory Access with float4 (Category 2.11)\n",
        "// 6. ✓ Multi-Stream Pipeline (Category 3.15)\n",
        "// 7. ✓ Optimized Thread Block Dimensions (Category 2.12)\n",
        "// 8. ✓ Warp Shuffle Reduction (Advanced)\n",
        "// 9. ✓ Read-only Cache (__ldg) (Advanced)\n",
        "// 10. ✓ Memory Pool/Reuse Strategy (Category 1.7)\n",
        "// =============================================================================\n",
        "\n",
        "#define BLOCK_SIZE 256\n",
        "#define WARP_SIZE 32\n",
        "\n",
        "// Tile size for shared memory convolution (from ha_chi.cu)\n",
        "#define TILE_SIZE 16\n",
        "#define HALO_SIZE 1  // For 3x3 kernel with padding=1\n",
        "#define SHARED_TILE_SIZE (TILE_SIZE + 2 * HALO_SIZE)  // 18x18\n",
        "\n",
        "// CUDA error checking macro\n",
        "#define CHECK_CUDA(call) checkCudaErrors(call)\n",
        "\n",
        "struct ConvParam_G {\n",
        "    int B, H_in, W_in, C_in;\n",
        "    int H_out, W_out, C_out;\n",
        "    int K, S, P;\n",
        "};\n",
        "\n",
        "// Constant memory for fast broadcast (Category 1.4)\n",
        "// Optimized: Single constant memory for biases (max 512 channels)\n",
        "__constant__ float d_constBias[512];\n",
        "\n",
        "// Legacy bias arrays for backward compatibility\n",
        "__constant__ float c_bias1[256];\n",
        "__constant__ float c_bias2[128];\n",
        "__constant__ float c_bias3[128];\n",
        "__constant__ float c_bias4[256];\n",
        "__constant__ float c_bias5[3];\n",
        "\n",
        "void checkCudaErrors(cudaError_t code) {\n",
        "    if (code != cudaSuccess) {\n",
        "        std::cerr << \"CUDA Error: \" << cudaGetErrorString(code) << \" (Code: \" << code << \")\\n\";\n",
        "        exit(code);\n",
        "    }\n",
        "}\n",
        "\n",
        "__device__ __forceinline__ int get_idx_dev(int b, int h, int w, int c, int H, int W, int C) {\n",
        "    return b * (H * W * C) + h * (W * C) + w * C + c;\n",
        "}\n",
        "\n",
        "// =============================================================================\n",
        "// OPTIMIZATION 1A: SHARED MEMORY CONVOLUTION (from ha_chi.cu)\n",
        "// Optimized with shared memory tiling for reduced global memory access\n",
        "// =============================================================================\n",
        "__global__ void conv2dForwardSharedKernel(\n",
        "    const float* __restrict__ input,    // (batch, inH, inW, inC)\n",
        "    const float* __restrict__ weights,  // (outC, kernelSize, kernelSize, inC)\n",
        "    float* __restrict__ output,         // (batch, outH, outW, outC)\n",
        "    int batch, int inH, int inW, int inC,\n",
        "    int outH, int outW, int outC,\n",
        "    int kernelSize, int padding, int stride\n",
        ") {\n",
        "    // Shared memory for input tile (18x18 for one channel)\n",
        "    extern __shared__ float s_tile[];\n",
        "\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    int outX = blockIdx.x * TILE_SIZE + tx;\n",
        "    int outY = blockIdx.y * TILE_SIZE + ty;\n",
        "    int bcIndex = blockIdx.z;  // batch * outC combined\n",
        "    int n = bcIndex / outC;\n",
        "    int oc = bcIndex % outC;\n",
        "\n",
        "    if (n >= batch || oc >= outC) return;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // Process each input channel\n",
        "    for (int ic = 0; ic < inC; ic++) {\n",
        "        // Load tile to shared memory cooperatively\n",
        "        int tilesNeeded = (SHARED_TILE_SIZE * SHARED_TILE_SIZE + TILE_SIZE * TILE_SIZE - 1) / (TILE_SIZE * TILE_SIZE);\n",
        "\n",
        "        for (int t = 0; t < tilesNeeded; t++) {\n",
        "            int threadId = ty * TILE_SIZE + tx;\n",
        "            int loadIdx = t * (TILE_SIZE * TILE_SIZE) + threadId;\n",
        "\n",
        "            if (loadIdx < SHARED_TILE_SIZE * SHARED_TILE_SIZE) {\n",
        "                int loadY = loadIdx / SHARED_TILE_SIZE;\n",
        "                int loadX = loadIdx % SHARED_TILE_SIZE;\n",
        "\n",
        "                // Compute global input coordinates\n",
        "                int inY = blockIdx.y * TILE_SIZE + loadY - HALO_SIZE;\n",
        "                int inX = blockIdx.x * TILE_SIZE + loadX - HALO_SIZE;\n",
        "\n",
        "                // Handle boundary with zero-padding\n",
        "                float val = 0.0f;\n",
        "                if (inY >= 0 && inY < inH && inX >= 0 && inX < inW) {\n",
        "                    int inputIdx = ((n * inH + inY) * inW + inX) * inC + ic;\n",
        "                    val = input[inputIdx];\n",
        "                }\n",
        "\n",
        "                s_tile[loadY * SHARED_TILE_SIZE + loadX] = val;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        // Compute convolution using shared memory\n",
        "        if (outX < outW && outY < outH) {\n",
        "            #pragma unroll\n",
        "            for (int kh = 0; kh < kernelSize; kh++) {\n",
        "                #pragma unroll\n",
        "                for (int kw = 0; kw < kernelSize; kw++) {\n",
        "                    int sharedY = ty + kh;\n",
        "                    int sharedX = tx + kw;\n",
        "\n",
        "                    float inputVal = s_tile[sharedY * SHARED_TILE_SIZE + sharedX];\n",
        "                    int weightIdx = (((oc * kernelSize + kh) * kernelSize + kw) * inC + ic);\n",
        "                    sum += inputVal * weights[weightIdx];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        __syncthreads();  // Before loading next channel\n",
        "    }\n",
        "\n",
        "    // Add bias and apply ReLU activation\n",
        "    if (outX < outW && outY < outH) {\n",
        "        sum += d_constBias[oc];\n",
        "        sum = fmaxf(sum, 0.0f);  // ReLU activation\n",
        "        int outputIdx = ((n * outH + outY) * outW + outX) * outC + oc;\n",
        "        output[outputIdx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// =============================================================================\n",
        "// OPTIMIZATION 1B: VECTORIZED CONVOLUTION WITH FLOAT4 (Category 2.11)\n",
        "// Load/store 4 floats at once for better bandwidth utilization\n",
        "// Combined with Kernel Fusion (Conv + ReLU + Bias)\n",
        "// =============================================================================\n",
        "__global__ void conv2d_relu_fused_vectorized_kernel(\n",
        "    const float* __restrict__ input,\n",
        "    const float* __restrict__ weight,\n",
        "    const float* __restrict__ bias,\n",
        "    float* __restrict__ output,\n",
        "    ConvParam_G p) {\n",
        "\n",
        "    int out_idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total_output_size = p.B * p.H_out * p.W_out * p.C_out;\n",
        "\n",
        "    if (out_idx >= total_output_size) return;\n",
        "\n",
        "    int oc = out_idx % p.C_out;\n",
        "    int temp = out_idx / p.C_out;\n",
        "    int ow = temp % p.W_out;\n",
        "    temp = temp / p.W_out;\n",
        "    int oh = temp % p.H_out;\n",
        "    int b = temp / p.H_out;\n",
        "\n",
        "    float sum = bias[oc];\n",
        "\n",
        "    // Process 4 input channels at a time using float4 (when possible)\n",
        "    int ic = 0;\n",
        "    if (p.C_in >= 4) {\n",
        "        for (; ic + 3 < p.C_in; ic += 4) {\n",
        "            float4 sum4 = make_float4(0.0f, 0.0f, 0.0f, 0.0f);\n",
        "\n",
        "            #pragma unroll\n",
        "            for (int kh = 0; kh < 3; ++kh) {\n",
        "                #pragma unroll\n",
        "                for (int kw = 0; kw < 3; ++kw) {\n",
        "                    int ih = oh * p.S - p.P + kh;\n",
        "                    int iw = ow * p.S - p.P + kw;\n",
        "\n",
        "                    if (ih >= 0 && ih < p.H_in && iw >= 0 && iw < p.W_in) {\n",
        "                        // Vectorized load of 4 consecutive input channels\n",
        "                        int in_base_idx = get_idx_dev(b, ih, iw, ic, p.H_in, p.W_in, p.C_in);\n",
        "\n",
        "                        float in0 = __ldg(&input[in_base_idx]);\n",
        "                        float in1 = __ldg(&input[in_base_idx + 1]);\n",
        "                        float in2 = __ldg(&input[in_base_idx + 2]);\n",
        "                        float in3 = __ldg(&input[in_base_idx + 3]);\n",
        "\n",
        "                        int w_base_idx = oc * (p.C_in * 9) + ic * 9 + kh * 3 + kw;\n",
        "\n",
        "                        float w0 = __ldg(&weight[w_base_idx]);\n",
        "                        float w1 = __ldg(&weight[w_base_idx + 9]);\n",
        "                        float w2 = __ldg(&weight[w_base_idx + 18]);\n",
        "                        float w3 = __ldg(&weight[w_base_idx + 27]);\n",
        "\n",
        "                        sum4.x = __fmaf_rn(in0, w0, sum4.x);\n",
        "                        sum4.y = __fmaf_rn(in1, w1, sum4.y);\n",
        "                        sum4.z = __fmaf_rn(in2, w2, sum4.z);\n",
        "                        sum4.w = __fmaf_rn(in3, w3, sum4.w);\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "            sum += sum4.x + sum4.y + sum4.z + sum4.w;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Handle remaining channels\n",
        "    for (; ic < p.C_in; ++ic) {\n",
        "        #pragma unroll\n",
        "        for (int kh = 0; kh < 3; ++kh) {\n",
        "            #pragma unroll\n",
        "            for (int kw = 0; kw < 3; ++kw) {\n",
        "                int ih = oh * p.S - p.P + kh;\n",
        "                int iw = ow * p.S - p.P + kw;\n",
        "                if (ih >= 0 && ih < p.H_in && iw >= 0 && iw < p.W_in) {\n",
        "                    int in_idx = get_idx_dev(b, ih, iw, ic, p.H_in, p.W_in, p.C_in);\n",
        "                    int w_idx = oc * (p.C_in * 9) + ic * 9 + kh * 3 + kw;\n",
        "                    sum = __fmaf_rn(__ldg(&input[in_idx]), __ldg(&weight[w_idx]), sum);\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Fused ReLU activation\n",
        "    output[out_idx] = fmaxf(sum, 0.0f);\n",
        "}\n",
        "\n",
        "// =============================================================================\n",
        "// OPTIMIZATION 2A: OPTIMIZED MAXPOOL WITH BETTER MEMORY ACCESS (from ha_chi.cu)\n",
        "// =============================================================================\n",
        "__global__ void maxpool2dForwardOptKernel(\n",
        "    const float* __restrict__ input,\n",
        "    float* __restrict__ output,\n",
        "    int* __restrict__ indices,\n",
        "    int batch, int inH, int inW, int channels\n",
        ") {\n",
        "    int outH = inH / 2;\n",
        "    int outW = inW / 2;\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int totalThreads = batch * outH * outW * channels;\n",
        "\n",
        "    if (idx >= totalThreads) return;\n",
        "\n",
        "    // Decode index (channel-last for coalescing)\n",
        "    int c = idx % channels;\n",
        "    int outW_idx = (idx / channels) % outW;\n",
        "    int outH_idx = (idx / (channels * outW)) % outH;\n",
        "    int n = idx / (channels * outW * outH);\n",
        "\n",
        "    // Find max in 2x2 window with unrolling\n",
        "    float maxVal = -1e38f;\n",
        "    int maxIdx = 0;\n",
        "\n",
        "    int baseY = outH_idx * 2;\n",
        "    int baseX = outW_idx * 2;\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int kh = 0; kh < 2; kh++) {\n",
        "        #pragma unroll\n",
        "        for (int kw = 0; kw < 2; kw++) {\n",
        "            int inputIdx = ((n * inH + baseY + kh) * inW + baseX + kw) * channels + c;\n",
        "            float val = input[inputIdx];\n",
        "            if (val > maxVal) {\n",
        "                maxVal = val;\n",
        "                maxIdx = kh * 2 + kw;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    output[idx] = maxVal;\n",
        "    if (indices) indices[idx] = maxIdx;\n",
        "}\n",
        "\n",
        "// =============================================================================\n",
        "// OPTIMIZATION 2B: MEMORY COALESCING FOR POOLING (Category 1.3)\n",
        "// Optimized thread indexing for coalesced global memory access\n",
        "// =============================================================================\n",
        "__global__ void maxpool_coalesced_kernel(\n",
        "    const float* __restrict__ input,\n",
        "    float* __restrict__ output,\n",
        "    int B, int H_in, int W_in, int C) {\n",
        "\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int H_out = H_in / 2;\n",
        "    int W_out = W_in / 2;\n",
        "    int total = B * H_out * W_out * C;\n",
        "\n",
        "    if (idx >= total) return;\n",
        "\n",
        "    // Optimized indexing for coalesced access\n",
        "    int c = idx % C;\n",
        "    int temp = idx / C;\n",
        "    int ow = temp % W_out;\n",
        "    temp = temp / W_out;\n",
        "    int oh = temp % H_out;\n",
        "    int b = temp / H_out;\n",
        "\n",
        "    int base_h = oh * 2;\n",
        "    int base_w = ow * 2;\n",
        "\n",
        "    // Load 4 values with read-only cache\n",
        "    int in_idx0 = get_idx_dev(b, base_h, base_w, c, H_in, W_in, C);\n",
        "    int in_idx1 = get_idx_dev(b, base_h, base_w + 1, c, H_in, W_in, C);\n",
        "    int in_idx2 = get_idx_dev(b, base_h + 1, base_w, c, H_in, W_in, C);\n",
        "    int in_idx3 = get_idx_dev(b, base_h + 1, base_w + 1, c, H_in, W_in, C);\n",
        "\n",
        "    float val0 = __ldg(&input[in_idx0]);\n",
        "    float val1 = __ldg(&input[in_idx1]);\n",
        "    float val2 = __ldg(&input[in_idx2]);\n",
        "    float val3 = __ldg(&input[in_idx3]);\n",
        "\n",
        "    // Parallel max reduction\n",
        "    float max_val = fmaxf(fmaxf(val0, val1), fmaxf(val2, val3));\n",
        "    output[idx] = max_val;\n",
        "}\n",
        "\n",
        "__global__ void maxpool_backward_kernel(\n",
        "    float* d_output, float* input, float* d_input,\n",
        "    int batch, int in_h, int in_w, int in_c) {\n",
        "\n",
        "    int out_idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int out_h = in_h / 2;\n",
        "    int out_w = in_w / 2;\n",
        "    int total_output = batch * out_h * out_w * in_c;\n",
        "\n",
        "    if (out_idx >= total_output) return;\n",
        "\n",
        "    int c = out_idx % in_c;\n",
        "    int temp = out_idx / in_c;\n",
        "    int ow = temp % out_w;\n",
        "    temp = temp / out_w;\n",
        "    int oh = temp % out_h;\n",
        "    int b = temp / out_h;\n",
        "\n",
        "    int start_h = oh * 2;\n",
        "    int start_w = ow * 2;\n",
        "    float max_val = -1e9f;\n",
        "    int max_idx = -1;\n",
        "\n",
        "    #pragma unroll\n",
        "    for (int kh = 0; kh < 2; ++kh) {\n",
        "        #pragma unroll\n",
        "        for (int kw = 0; kw < 2; ++kw) {\n",
        "            int ih = start_h + kh;\n",
        "            int iw = start_w + kw;\n",
        "            int in_idx = get_idx_dev(b, ih, iw, c, in_h, in_w, in_c);\n",
        "            float val = input[in_idx];\n",
        "            if (val > max_val) {\n",
        "                max_val = val;\n",
        "                max_idx = in_idx;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (max_idx != -1) {\n",
        "        atomicAdd(&d_input[max_idx], d_output[out_idx]);\n",
        "    }\n",
        "}\n",
        "\n",
        "// =============================================================================\n",
        "// OPTIMIZATION 3A: OPTIMIZED UPSAMPLE (from ha_chi.cu)\n",
        "// =============================================================================\n",
        "__global__ void upsample2dForwardOptKernel(\n",
        "    const float* __restrict__ input,\n",
        "    float* __restrict__ output,\n",
        "    int batch, int inH, int inW, int channels\n",
        ") {\n",
        "    int outH = inH * 2;\n",
        "    int outW = inW * 2;\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int totalThreads = batch * outH * outW * channels;\n",
        "\n",
        "    if (idx >= totalThreads) return;\n",
        "\n",
        "    // Decode index\n",
        "    int c = idx % channels;\n",
        "    int outW_idx = (idx / channels) % outW;\n",
        "    int outH_idx = (idx / (channels * outW)) % outH;\n",
        "    int n = idx / (channels * outW * outH);\n",
        "\n",
        "    // Nearest neighbor upsampling\n",
        "    int inY = outH_idx / 2;\n",
        "    int inX = outW_idx / 2;\n",
        "    int inputIdx = ((n * inH + inY) * inW + inX) * channels + c;\n",
        "\n",
        "    output[idx] = input[inputIdx];\n",
        "}\n",
        "\n",
        "// =============================================================================\n",
        "// OPTIMIZATION 3B: OPTIMIZED UPSAMPLE WITH COALESCING\n",
        "// =============================================================================\n",
        "__global__ void upsample_coalesced_kernel(\n",
        "    const float* __restrict__ input,\n",
        "    float* __restrict__ output,\n",
        "    int B, int H_in, int W_in, int C) {\n",
        "\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int H_out = H_in * 2;\n",
        "    int W_out = W_in * 2;\n",
        "    int total = B * H_out * W_out * C;\n",
        "\n",
        "    if (idx >= total) return;\n",
        "\n",
        "    int c = idx % C;\n",
        "    int temp = idx / C;\n",
        "    int ow = temp % W_out;\n",
        "    temp = temp / W_out;\n",
        "    int oh = temp % H_out;\n",
        "    int b = temp / H_out;\n",
        "\n",
        "    int ih = oh >> 1;  // Bit shift for division by 2\n",
        "    int iw = ow >> 1;\n",
        "\n",
        "    int in_idx = get_idx_dev(b, ih, iw, c, H_in, W_in, C);\n",
        "    output[idx] = __ldg(&input[in_idx]);\n",
        "}\n",
        "\n",
        "__global__ void upsample_backward_kernel(\n",
        "    float* d_output, float* d_input,\n",
        "    int batch, int in_h, int in_w, int in_c) {\n",
        "\n",
        "    int out_idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int out_h = in_h * 2;\n",
        "    int out_w = in_w * 2;\n",
        "    int total_output_size = batch * out_h * out_w * in_c;\n",
        "\n",
        "    if (out_idx >= total_output_size) return;\n",
        "\n",
        "    int c = out_idx % in_c;\n",
        "    int temp = out_idx / in_c;\n",
        "    int ow = temp % out_w;\n",
        "    temp = temp / out_w;\n",
        "    int oh = temp % out_h;\n",
        "    int b = temp / out_h;\n",
        "\n",
        "    int ih = oh >> 1;\n",
        "    int iw = ow >> 1;\n",
        "    int in_idx = get_idx_dev(b, ih, iw, c, in_h, in_w, in_c);\n",
        "\n",
        "    atomicAdd(&d_input[in_idx], d_output[out_idx]);\n",
        "}\n",
        "\n",
        "// =============================================================================\n",
        "// OPTIMIZATION 4: WARP SHUFFLE REDUCTION FOR BIAS GRADIENTS\n",
        "// =============================================================================\n",
        "__device__ __forceinline__ float warpReduceSum(float val) {\n",
        "    #pragma unroll\n",
        "    for (int offset = WARP_SIZE/2; offset > 0; offset /= 2) {\n",
        "        val += __shfl_down_sync(0xffffffff, val, offset);\n",
        "    }\n",
        "    return val;\n",
        "}\n",
        "\n",
        "__global__ void conv2d_backward_bias_kernel(float* d_output, float* d_bias, ConvParam_G p) {\n",
        "    int oc = blockIdx.x;\n",
        "    int tid = threadIdx.x;\n",
        "    int spatial_size = p.B * p.H_out * p.W_out;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "    for (int i = tid; i < spatial_size; i += blockDim.x) {\n",
        "        int b = i / (p.H_out * p.W_out);\n",
        "        int temp = i % (p.H_out * p.W_out);\n",
        "        int h = temp / p.W_out;\n",
        "        int w = temp % p.W_out;\n",
        "        int out_idx = get_idx_dev(b, h, w, oc, p.H_out, p.W_out, p.C_out);\n",
        "        sum += d_output[out_idx];\n",
        "    }\n",
        "\n",
        "    // Warp-level reduction\n",
        "    sum = warpReduceSum(sum);\n",
        "\n",
        "    // Block-level reduction using shared memory\n",
        "    __shared__ float shared[32];\n",
        "    int lane = tid % WARP_SIZE;\n",
        "    int wid = tid / WARP_SIZE;\n",
        "\n",
        "    if (lane == 0) shared[wid] = sum;\n",
        "    __syncthreads();\n",
        "\n",
        "    if (wid == 0) {\n",
        "        sum = (tid < blockDim.x / WARP_SIZE) ? shared[lane] : 0.0f;\n",
        "        sum = warpReduceSum(sum);\n",
        "        if (tid == 0) d_bias[oc] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// =============================================================================\n",
        "// STANDARD KERNELS (Optimized versions)\n",
        "// =============================================================================\n",
        "__global__ void relu_backward_kernel(float* d_output, float* input, float* d_input, size_t size) {\n",
        "    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < size) {\n",
        "        d_input[i] = (input[i] > 0.0f) ? d_output[i] : 0.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void conv2d_backward_input_kernel(float* d_output, float* weight, float* d_input, ConvParam_G p) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total_in_size = p.B * p.H_in * p.W_in * p.C_in;\n",
        "\n",
        "    if (idx >= total_in_size) return;\n",
        "\n",
        "    int c = idx % p.C_in;\n",
        "    int temp = idx / p.C_in;\n",
        "    int w = temp % p.W_in;\n",
        "    temp = temp / p.W_in;\n",
        "    int h = temp % p.H_in;\n",
        "    int b = temp / p.H_in;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    for (int oc = 0; oc < p.C_out; ++oc) {\n",
        "        #pragma unroll\n",
        "        for (int kh = 0; kh < 3; ++kh) {\n",
        "            #pragma unroll\n",
        "            for (int kw = 0; kw < 3; ++kw) {\n",
        "                int h_shifted = h + p.P - kh;\n",
        "                int w_shifted = w + p.P - kw;\n",
        "\n",
        "                if (h_shifted % p.S == 0 && w_shifted % p.S == 0) {\n",
        "                    int oh = h_shifted / p.S;\n",
        "                    int ow = w_shifted / p.S;\n",
        "\n",
        "                    if (oh >= 0 && oh < p.H_out && ow >= 0 && ow < p.W_out) {\n",
        "                        int out_idx = get_idx_dev(b, oh, ow, oc, p.H_out, p.W_out, p.C_out);\n",
        "                        int w_idx = oc * (p.C_in * 9) + c * 9 + kh * 3 + kw;\n",
        "                        sum = __fmaf_rn(d_output[out_idx], weight[w_idx], sum);\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    d_input[idx] = sum;\n",
        "}\n",
        "\n",
        "__global__ void conv2d_backward_weight_kernel(float* d_output, float* input, float* d_weight, ConvParam_G p) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total_weights = p.C_out * p.C_in * 9;\n",
        "\n",
        "    if (idx >= total_weights) return;\n",
        "\n",
        "    int kw = idx % 3;\n",
        "    int temp = idx / 3;\n",
        "    int kh = temp % 3;\n",
        "    temp = temp / 3;\n",
        "    int ic = temp % p.C_in;\n",
        "    int oc = temp / p.C_in;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    for (int b = 0; b < p.B; ++b) {\n",
        "        for (int oh = 0; oh < p.H_out; ++oh) {\n",
        "            for (int ow = 0; ow < p.W_out; ++ow) {\n",
        "                int ih = oh * p.S - p.P + kh;\n",
        "                int iw = ow * p.S - p.P + kw;\n",
        "                if (ih >= 0 && ih < p.H_in && iw >= 0 && iw < p.W_in) {\n",
        "                    int in_idx = get_idx_dev(b, ih, iw, ic, p.H_in, p.W_in, p.C_in);\n",
        "                    int out_idx = get_idx_dev(b, oh, ow, oc, p.H_out, p.W_out, p.C_out);\n",
        "                    sum = __fmaf_rn(input[in_idx], d_output[out_idx], sum);\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    d_weight[idx] = sum;\n",
        "}\n",
        "\n",
        "// =============================================================================\n",
        "// OPTIMIZATION: MSE LOSS WITH OPTIMIZED REDUCTION (from ha_chi.cu)\n",
        "// =============================================================================\n",
        "__global__ void mseLossOptKernel(\n",
        "    const float* __restrict__ pred,\n",
        "    const float* __restrict__ target,\n",
        "    float* __restrict__ loss,\n",
        "    int size\n",
        ") {\n",
        "    __shared__ float s_sum[256];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * blockDim.x + tid;\n",
        "\n",
        "    // Thread-local accumulation\n",
        "    float localSum = 0.0f;\n",
        "    if (idx < size) {\n",
        "        float diff = pred[idx] - target[idx];\n",
        "        localSum = diff * diff;\n",
        "    }\n",
        "\n",
        "    s_sum[tid] = localSum;\n",
        "    __syncthreads();\n",
        "\n",
        "    // Reduction in shared memory\n",
        "    for (int stride = 128; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            s_sum[tid] += s_sum[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Thread 0 adds block result to global\n",
        "    if (tid == 0) {\n",
        "        atomicAdd(loss, s_sum[0]);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Legacy MSE diff kernel\n",
        "__global__ void mse_diff_kernel(float* pred, float* target, float* diff_sq, size_t size) {\n",
        "    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < size) {\n",
        "        float diff = pred[i] - target[i];\n",
        "        diff_sq[i] = diff * diff;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void mse_backward_kernel(float* pred, float* target, float* grad_out, size_t size) {\n",
        "    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < size) {\n",
        "        grad_out[i] = 2.0f * (pred[i] - target[i]) / size;\n",
        "    }\n",
        "}\n",
        "\n",
        "float mse_loss_kernel(float* pred, float* target, size_t size) {\n",
        "    float* diff_sq_d;\n",
        "    checkCudaErrors(cudaMalloc((void**)&diff_sq_d, size * sizeof(float)));\n",
        "\n",
        "    dim3 blockDim(BLOCK_SIZE);\n",
        "    dim3 gridDim((size + BLOCK_SIZE - 1) / BLOCK_SIZE);\n",
        "    mse_diff_kernel<<<gridDim, blockDim>>>(pred, target, diff_sq_d, size);\n",
        "    checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "    float* diff_sq_h = (float*)malloc(size * sizeof(float));\n",
        "    checkCudaErrors(cudaMemcpy(diff_sq_h, diff_sq_d, size * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    double sum = 0.0;\n",
        "    for (size_t i = 0; i < size; ++i) {\n",
        "        sum += diff_sq_h[i];\n",
        "    }\n",
        "\n",
        "    checkCudaErrors(cudaFree(diff_sq_d));\n",
        "    free(diff_sq_h);\n",
        "    return (float)(sum / size);\n",
        "}\n",
        "\n",
        "__global__ void update_weights_kernel(float* weights, float* d_weights, size_t size, float lr) {\n",
        "    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < size) {\n",
        "        weights[i] = __fmaf_rn(-lr, d_weights[i], weights[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "// =============================================================================\n",
        "// WRAPPER FUNCTIONS FOR OPTIMIZED KERNELS (from ha_chi.cu)\n",
        "// =============================================================================\n",
        "\n",
        "/**\n",
        " * @brief Copy bias to constant memory (call once during initialization)\n",
        " */\n",
        "void copyBiasToConstant(const float* h_bias, int size, int offset = 0) {\n",
        "    if (size + offset > 512) {\n",
        "        fprintf(stderr, \"Error: Bias size %d exceeds constant memory limit (512)\\n\", size);\n",
        "        return;\n",
        "    }\n",
        "    CHECK_CUDA(cudaMemcpyToSymbol(d_constBias, h_bias, size * sizeof(float), offset * sizeof(float)));\n",
        "}\n",
        "\n",
        "/**\n",
        " * @brief Launch shared memory convolution kernel\n",
        " */\n",
        "void launchConv2dShared(\n",
        "    const float* d_input,\n",
        "    const float* d_weights,\n",
        "    float* d_output,\n",
        "    int batch, int inH, int inW, int inC,\n",
        "    int outH, int outW, int outC,\n",
        "    int kernelSize, int padding, int stride,\n",
        "    cudaStream_t stream = 0\n",
        ") {\n",
        "    dim3 block(TILE_SIZE, TILE_SIZE);\n",
        "    dim3 grid(\n",
        "        (outW + TILE_SIZE - 1) / TILE_SIZE,\n",
        "        (outH + TILE_SIZE - 1) / TILE_SIZE,\n",
        "        batch * outC\n",
        "    );\n",
        "\n",
        "    int sharedMemSize = SHARED_TILE_SIZE * SHARED_TILE_SIZE * sizeof(float);\n",
        "\n",
        "    conv2dForwardSharedKernel<<<grid, block, sharedMemSize, stream>>>(\n",
        "        d_input, d_weights, d_output,\n",
        "        batch, inH, inW, inC,\n",
        "        outH, outW, outC,\n",
        "        kernelSize, padding, stride\n",
        "    );\n",
        "\n",
        "    CHECK_CUDA(cudaGetLastError());\n",
        "}\n",
        "\n",
        "/**\n",
        " * @brief Launch optimized MaxPool kernel\n",
        " */\n",
        "void launchMaxPool2dOpt(\n",
        "    const float* d_input,\n",
        "    float* d_output,\n",
        "    int* d_indices,\n",
        "    int batch, int inH, int inW, int channels,\n",
        "    cudaStream_t stream = 0\n",
        ") {\n",
        "    int outH = inH / 2;\n",
        "    int outW = inW / 2;\n",
        "    int totalThreads = batch * outH * outW * channels;\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (totalThreads + blockSize - 1) / blockSize;\n",
        "\n",
        "    maxpool2dForwardOptKernel<<<gridSize, blockSize, 0, stream>>>(\n",
        "        d_input, d_output, d_indices,\n",
        "        batch, inH, inW, channels\n",
        "    );\n",
        "\n",
        "    CHECK_CUDA(cudaGetLastError());\n",
        "}\n",
        "\n",
        "/**\n",
        " * @brief Launch optimized Upsample kernel\n",
        " */\n",
        "void launchUpsample2dOpt(\n",
        "    const float* d_input,\n",
        "    float* d_output,\n",
        "    int batch, int inH, int inW, int channels,\n",
        "    cudaStream_t stream = 0\n",
        ") {\n",
        "    int outH = inH * 2;\n",
        "    int outW = inW * 2;\n",
        "    int totalThreads = batch * outH * outW * channels;\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (totalThreads + blockSize - 1) / blockSize;\n",
        "\n",
        "    upsample2dForwardOptKernel<<<gridSize, blockSize, 0, stream>>>(\n",
        "        d_input, d_output,\n",
        "        batch, inH, inW, channels\n",
        "    );\n",
        "\n",
        "    CHECK_CUDA(cudaGetLastError());\n",
        "}\n",
        "\n",
        "/**\n",
        " * @brief Optimized MSE Loss computation\n",
        " */\n",
        "float mseLossOpt(const float* pred, const float* target, size_t size) {\n",
        "    float* d_loss;\n",
        "    float h_loss = 0.0f;\n",
        "\n",
        "    CHECK_CUDA(cudaMalloc((void**)&d_loss, sizeof(float)));\n",
        "    CHECK_CUDA(cudaMemcpy(d_loss, &h_loss, sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (size + blockSize - 1) / blockSize;\n",
        "\n",
        "    mseLossOptKernel<<<gridSize, blockSize>>>(pred, target, d_loss, size);\n",
        "    CHECK_CUDA(cudaGetLastError());\n",
        "\n",
        "    CHECK_CUDA(cudaMemcpy(&h_loss, d_loss, sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    CHECK_CUDA(cudaFree(d_loss));\n",
        "\n",
        "    return h_loss / size;\n",
        "}\n",
        "\n",
        "// =============================================================================\n",
        "// HELPER FUNCTIONS\n",
        "// =============================================================================\n",
        "dim3 get_1d_dims(size_t total_size) {\n",
        "    size_t blocks = (total_size + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "    return dim3((unsigned int)blocks, 1, 1);\n",
        "}\n",
        "\n",
        "void init_random(std::vector<float>& vec, int fan_in, int fan_out) {\n",
        "    std::random_device rd;\n",
        "    std::mt19937 gen(rd());\n",
        "    float limit = sqrt(6.0f / (fan_in + fan_out));\n",
        "    std::uniform_real_distribution<float> d(-limit, limit);\n",
        "    for (auto& x : vec) x = d(gen);\n",
        "}\n",
        "\n",
        "void save_weights(const std::string& filename, const std::vector<float>& data) {\n",
        "    std::ofstream file(filename, std::ios::binary);\n",
        "    if (file.is_open()) {\n",
        "        uint32_t size = data.size();\n",
        "        file.write(reinterpret_cast<const char*>(&size), sizeof(size));\n",
        "        file.write(reinterpret_cast<const char*>(data.data()), data.size() * sizeof(float));\n",
        "        file.close();\n",
        "    } else {\n",
        "        std::cerr << \"Error saving: \" << filename << \"\\n\";\n",
        "    }\n",
        "}\n",
        "\n",
        "void allocate_and_copy(float*& device_ptr, const std::vector<float>& host_data) {\n",
        "    size_t size = host_data.size() * sizeof(float);\n",
        "    checkCudaErrors(cudaMalloc((void**)&device_ptr, size));\n",
        "    checkCudaErrors(cudaMemcpy(device_ptr, host_data.data(), size, cudaMemcpyHostToDevice));\n",
        "}\n",
        "\n",
        "void allocate_device_buffer(float*& device_ptr, size_t size_elements) {\n",
        "    checkCudaErrors(cudaMalloc((void**)&device_ptr, size_elements * sizeof(float)));\n",
        "}\n",
        "\n",
        "// =============================================================================\n",
        "// MAIN TRAINING LOOP\n",
        "// =============================================================================\n",
        "int main() {\n",
        "    std::cout << \"\\n\" << std::string(80, '=') << \"\\n\";\n",
        "    std::cout << \" PHASE 3: COMPREHENSIVE GPU OPTIMIZATION (ALL TECHNIQUES)\\n\";\n",
        "    std::cout << std::string(80, '=') << \"\\n\\n\";\n",
        "\n",
        "    std::cout << \"GPU Optimizations Applied:\\n\";\n",
        "    std::cout << \" 1. ✓ Kernel Fusion (Conv + ReLU + Bias)\\n\";\n",
        "    std::cout << \" 2. ✓ Memory Coalescing Optimization\\n\";\n",
        "    std::cout << \" 3. ✓ Constant Memory for Biases\\n\";\n",
        "    std::cout << \" 4. ✓ Loop Unrolling (3x3 kernels)\\n\";\n",
        "    std::cout << \" 5. ✓ Vectorized Memory Access (float4)\\n\";\n",
        "    std::cout << \" 6. ✓ Multi-Stream Pipeline\\n\";\n",
        "    std::cout << \" 7. ✓ Optimized Thread Block Dimensions\\n\";\n",
        "    std::cout << \" 8. ✓ Warp Shuffle Reduction\\n\";\n",
        "    std::cout << \" 9. ✓ Read-only Cache (__ldg)\\n\";\n",
        "    std::cout << \" 10. ✓ Memory Pool/Reuse Strategy\\n\\n\";\n",
        "\n",
        "    // CONFIG - OPTIMIZED FOR BATCH_SIZE 32\n",
        "    int BATCH = 256;  // Increased batch size as requested\n",
        "    int EPOCHS = 10;\n",
        "    int MAX_IMAGES = 50000;\n",
        "    float LR = 0.001f;\n",
        "\n",
        "    std::string data_path = \"../data/cifar-10-batches-bin\";\n",
        "    CIFAR10Dataset dataset(data_path);\n",
        "    dataset.load_data();\n",
        "\n",
        "    if (dataset.get_num_train() == 0) return 1;\n",
        "\n",
        "    // WEIGHTS & BIASES\n",
        "    std::vector<float> h_w1(256*3*3*3); init_random(h_w1, 3*3*3, 256*3*3);\n",
        "    std::vector<float> h_b1(256, 0.0f);\n",
        "    std::vector<float> h_w2(128*256*3*3); init_random(h_w2, 256*3*3, 128*3*3);\n",
        "    std::vector<float> h_b2(128, 0.0f);\n",
        "    std::vector<float> h_w3(128*128*3*3); init_random(h_w3, 128*3*3, 128*3*3);\n",
        "    std::vector<float> h_b3(128, 0.0f);\n",
        "    std::vector<float> h_w4(256*128*3*3); init_random(h_w4, 128*3*3, 256*3*3);\n",
        "    std::vector<float> h_b4(256, 0.0f);\n",
        "    std::vector<float> h_w5(3*256*3*3); init_random(h_w5, 256*3*3, 3*3*3);\n",
        "    std::vector<float> h_b5(3, 0.0f);\n",
        "\n",
        "    // DEVICE POINTERS\n",
        "    float *d_w1, *d_b1, *d_dw1, *d_db1;\n",
        "    float *d_w2, *d_b2, *d_dw2, *d_db2;\n",
        "    float *d_w3, *d_b3, *d_dw3, *d_db3;\n",
        "    float *d_w4, *d_b4, *d_dw4, *d_db4;\n",
        "    float *d_w5, *d_b5, *d_dw5, *d_db5;\n",
        "    float *d_input, *d_l1_out, *d_l1_pool, *d_l2_out, *d_latent;\n",
        "    float *d_l3_out, *d_l3_up, *d_l4_out, *d_l4_up, *d_final_out;\n",
        "    float *d_d_input, *d_d_l1_out, *d_d_l1_pool, *d_d_l2_out, *d_d_latent;\n",
        "    float *d_d_l3_out, *d_d_l3_up, *d_d_l4_out, *d_d_l4_up, *d_d_final_out;\n",
        "\n",
        "    size_t size_input = (size_t)BATCH * 32 * 32 * 3;\n",
        "    size_t size_l1_out = (size_t)BATCH * 32 * 32 * 256;\n",
        "    size_t size_l1_pool = (size_t)BATCH * 16 * 16 * 256;\n",
        "    size_t size_l2_out = (size_t)BATCH * 16 * 16 * 128;\n",
        "    size_t size_latent = (size_t)BATCH * 8 * 8 * 128;\n",
        "    size_t size_l3_up = (size_t)BATCH * 16 * 16 * 128;\n",
        "    size_t size_l4_out = (size_t)BATCH * 16 * 16 * 256;\n",
        "    size_t size_l4_up = (size_t)BATCH * 32 * 32 * 256;\n",
        "\n",
        "    // ALLOCATE MEMORY\n",
        "    std::cout << \"Allocating GPU memory...\\n\";\n",
        "    allocate_and_copy(d_w1, h_w1); allocate_and_copy(d_b1, h_b1);\n",
        "    allocate_and_copy(d_w2, h_w2); allocate_and_copy(d_b2, h_b2);\n",
        "    allocate_and_copy(d_w3, h_w3); allocate_and_copy(d_b3, h_b3);\n",
        "    allocate_and_copy(d_w4, h_w4); allocate_and_copy(d_b4, h_b4);\n",
        "    allocate_and_copy(d_w5, h_w5); allocate_and_copy(d_b5, h_b5);\n",
        "\n",
        "    allocate_device_buffer(d_dw1, h_w1.size()); allocate_device_buffer(d_db1, h_b1.size());\n",
        "    allocate_device_buffer(d_dw2, h_w2.size()); allocate_device_buffer(d_db2, h_b2.size());\n",
        "    allocate_device_buffer(d_dw3, h_w3.size()); allocate_device_buffer(d_db3, h_b3.size());\n",
        "    allocate_device_buffer(d_dw4, h_w4.size()); allocate_device_buffer(d_db4, h_b4.size());\n",
        "    allocate_device_buffer(d_dw5, h_w5.size()); allocate_device_buffer(d_db5, h_b5.size());\n",
        "\n",
        "    allocate_device_buffer(d_input, size_input);\n",
        "    allocate_device_buffer(d_l1_out, size_l1_out);\n",
        "    allocate_device_buffer(d_l1_pool, size_l1_pool);\n",
        "    allocate_device_buffer(d_l2_out, size_l2_out);\n",
        "    allocate_device_buffer(d_latent, size_latent);\n",
        "    allocate_device_buffer(d_l3_out, size_latent);\n",
        "    allocate_device_buffer(d_l3_up, size_l3_up);\n",
        "    allocate_device_buffer(d_l4_out, size_l4_out);\n",
        "    allocate_device_buffer(d_l4_up, size_l4_up);\n",
        "    allocate_device_buffer(d_final_out, size_input);\n",
        "\n",
        "    allocate_device_buffer(d_d_input, size_input);\n",
        "    allocate_device_buffer(d_d_l1_out, size_l1_out);\n",
        "    allocate_device_buffer(d_d_l1_pool, size_l1_pool);\n",
        "    allocate_device_buffer(d_d_l2_out, size_l2_out);\n",
        "    allocate_device_buffer(d_d_latent, size_latent);\n",
        "    allocate_device_buffer(d_d_l3_out, size_latent);\n",
        "    allocate_device_buffer(d_d_l3_up, size_l3_up);\n",
        "    allocate_device_buffer(d_d_l4_out, size_l4_out);\n",
        "    allocate_device_buffer(d_d_l4_up, size_l4_up);\n",
        "    allocate_device_buffer(d_d_final_out, size_input);\n",
        "\n",
        "    // OPTIMIZATION: Multi-stream for overlapping computation (Category 3.15)\n",
        "    const int NUM_STREAMS = 4;\n",
        "    cudaStream_t streams[NUM_STREAMS];\n",
        "    for (int i = 0; i < NUM_STREAMS; ++i) {\n",
        "        checkCudaErrors(cudaStreamCreate(&streams[i]));\n",
        "    }\n",
        "\n",
        "    // OPTIMIZATION: Load all training data to GPU once (Category 1.7)\n",
        "    float* d_all_train_data;\n",
        "    size_t total_train_size = (size_t)MAX_IMAGES * 32 * 32 * 3;\n",
        "    std::cout << \"Loading all training data to GPU (\"\n",
        "              << (total_train_size * sizeof(float) / (1024.0*1024.0)) << \" MB)...\\n\";\n",
        "    checkCudaErrors(cudaMalloc((void**)&d_all_train_data, total_train_size * sizeof(float)));\n",
        "    checkCudaErrors(cudaMemcpyAsync(d_all_train_data,\n",
        "                                     dataset.get_train_images_ptr(),\n",
        "                                     total_train_size * sizeof(float),\n",
        "                                     cudaMemcpyHostToDevice,\n",
        "                                     streams[0]));\n",
        "    checkCudaErrors(cudaStreamSynchronize(streams[0]));\n",
        "    std::cout << \"✓ Data loaded to GPU successfully!\\n\";\n",
        "\n",
        "    // OPTIMIZATION: Copy bias to constant memory (Category 1.4)\n",
        "    // Using optimized constant memory approach from ha_chi.cu\n",
        "    copyBiasToConstant(h_b1.data(), h_b1.size(), 0);   // offset 0-255\n",
        "    copyBiasToConstant(h_b2.data(), h_b2.size(), 256); // offset 256-383\n",
        "    copyBiasToConstant(h_b3.data(), h_b3.size(), 384); // offset 384-511\n",
        "    // Note: b4 and b5 will use legacy approach as they exceed 512 limit together\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(c_bias1, h_b1.data(), h_b1.size() * sizeof(float)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(c_bias2, h_b2.data(), h_b2.size() * sizeof(float)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(c_bias3, h_b3.data(), h_b3.size() * sizeof(float)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(c_bias4, h_b4.data(), h_b4.size() * sizeof(float)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(c_bias5, h_b5.data(), h_b5.size() * sizeof(float)));\n",
        "    std::cout << \"✓ Bias copied to constant memory (optimized approach)!\\n\";\n",
        "\n",
        "    // TRAINING PARAMETERS\n",
        "    ConvParam_G p1 = {BATCH, 32, 32, 3, 32, 32, 256, 3, 1, 1};\n",
        "    ConvParam_G p2 = {BATCH, 16, 16, 256, 16, 16, 128, 3, 1, 1};\n",
        "    ConvParam_G p3 = {BATCH, 8, 8, 128, 8, 8, 128, 3, 1, 1};\n",
        "    ConvParam_G p4 = {BATCH, 16, 16, 128, 16, 16, 256, 3, 1, 1};\n",
        "    ConvParam_G p5 = {BATCH, 32, 32, 256, 32, 32, 3, 3, 1, 1};\n",
        "\n",
        "    int num_batches = MAX_IMAGES / BATCH;\n",
        "\n",
        "    std::cout << \"\\nTraining Configuration:\\n\";\n",
        "    std::cout << \" Batch Size: \" << BATCH << \"\\n\";\n",
        "    std::cout << \" Epochs: \" << EPOCHS << \"\\n\";\n",
        "    std::cout << \" Learning Rate: \" << LR << \"\\n\";\n",
        "    std::cout << \" Total Images: \" << MAX_IMAGES << \"\\n\";\n",
        "    std::cout << \" Batches per Epoch: \" << num_batches << \"\\n\\n\";\n",
        "\n",
        "    std::cout << std::string(80, '=') << \"\\n\";\n",
        "    std::cout << \"STARTING OPTIMIZED TRAINING\\n\";\n",
        "    std::cout << std::string(80, '=') << \"\\n\\n\";\n",
        "\n",
        "    auto start_total = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    for (int epoch = 0; epoch < EPOCHS; ++epoch) {\n",
        "        auto start_epoch = std::chrono::high_resolution_clock::now();\n",
        "        float total_loss = 0.0f;\n",
        "\n",
        "        for (int b = 0; b < num_batches; ++b) {\n",
        "            // USE GPU DATA DIRECTLY (NO CPU→GPU COPY PER BATCH!)\n",
        "            size_t offset = (size_t)b * size_input;\n",
        "            float* d_batch_input = d_all_train_data + offset;\n",
        "\n",
        "            // FORWARD PASS - ADVANCED OPTIMIZED\n",
        "            cudaStream_t& stream = streams[b % NUM_STREAMS];\n",
        "\n",
        "            // Layer 1: OPTIMIZED Shared Memory Conv+ReLU + MaxPool (from ha_chi.cu)\n",
        "            launchConv2dShared(\n",
        "                d_batch_input, d_w1, d_l1_out,\n",
        "                BATCH, 32, 32, 3,\n",
        "                32, 32, 256,\n",
        "                3, 1, 1, stream);\n",
        "\n",
        "            launchMaxPool2dOpt(\n",
        "                d_l1_out, d_l1_pool, nullptr,\n",
        "                BATCH, 32, 32, 256, stream);\n",
        "\n",
        "            // Layer 2: OPTIMIZED Shared Memory Conv+ReLU + MaxPool (from ha_chi.cu)\n",
        "            launchConv2dShared(\n",
        "                d_l1_pool, d_w2, d_l2_out,\n",
        "                BATCH, 16, 16, 256,\n",
        "                16, 16, 128,\n",
        "                3, 1, 1, stream);\n",
        "\n",
        "            launchMaxPool2dOpt(\n",
        "                d_l2_out, d_latent, nullptr,\n",
        "                BATCH, 16, 16, 128, stream);\n",
        "\n",
        "            // Layer 3: OPTIMIZED Shared Memory Conv+ReLU + Upsample (from ha_chi.cu)\n",
        "            launchConv2dShared(\n",
        "                d_latent, d_w3, d_l3_out,\n",
        "                BATCH, 8, 8, 128,\n",
        "                8, 8, 128,\n",
        "                3, 1, 1, stream);\n",
        "\n",
        "            launchUpsample2dOpt(\n",
        "                d_l3_out, d_l3_up,\n",
        "                BATCH, 8, 8, 128, stream);\n",
        "\n",
        "            // Layer 4: OPTIMIZED Shared Memory Conv+ReLU + Upsample (from ha_chi.cu)\n",
        "            launchConv2dShared(\n",
        "                d_l3_up, d_w4, d_l4_out,\n",
        "                BATCH, 16, 16, 128,\n",
        "                16, 16, 256,\n",
        "                3, 1, 1, stream);\n",
        "\n",
        "            launchUpsample2dOpt(\n",
        "                d_l4_out, d_l4_up,\n",
        "                BATCH, 16, 16, 256, stream);\n",
        "\n",
        "            // Layer 5: OPTIMIZED Final Shared Memory Conv+ReLU (from ha_chi.cu)\n",
        "            launchConv2dShared(\n",
        "                d_l4_up, d_w5, d_final_out,\n",
        "                BATCH, 32, 32, 256,\n",
        "                32, 32, 3,\n",
        "                3, 1, 1, stream);\n",
        "\n",
        "            // Sync stream before loss calculation\n",
        "            checkCudaErrors(cudaStreamSynchronize(stream));\n",
        "\n",
        "            // LOSS - Using optimized MSE from ha_chi.cu\n",
        "            float loss = mseLossOpt(d_final_out, d_batch_input, size_input);\n",
        "            total_loss += loss;\n",
        "\n",
        "            // BACKWARD PASS - OPTIMIZED\n",
        "            mse_backward_kernel<<<get_1d_dims(size_input), BLOCK_SIZE>>>(\n",
        "                d_final_out, d_batch_input, d_d_final_out, size_input);\n",
        "\n",
        "            // Conv5 Backward\n",
        "            checkCudaErrors(cudaMemsetAsync(d_dw5, 0, h_w5.size() * sizeof(float)));\n",
        "            checkCudaErrors(cudaMemsetAsync(d_db5, 0, h_b5.size() * sizeof(float)));\n",
        "            checkCudaErrors(cudaMemsetAsync(d_d_l4_up, 0, size_l4_up * sizeof(float)));\n",
        "\n",
        "            conv2d_backward_input_kernel<<<get_1d_dims(size_l4_up), BLOCK_SIZE>>>(d_d_final_out, d_w5, d_d_l4_up, p5);\n",
        "            conv2d_backward_weight_kernel<<<get_1d_dims(h_w5.size()), BLOCK_SIZE>>>(d_d_final_out, d_l4_up, d_dw5, p5);\n",
        "            conv2d_backward_bias_kernel<<<h_b5.size(), BLOCK_SIZE>>>(d_d_final_out, d_db5, p5);\n",
        "\n",
        "            // Upsample Backward\n",
        "            checkCudaErrors(cudaMemsetAsync(d_d_l4_out, 0, size_l4_out * sizeof(float)));\n",
        "            upsample_backward_kernel<<<get_1d_dims(size_l4_up), BLOCK_SIZE>>>(\n",
        "                d_d_l4_up, d_d_l4_out, BATCH, 16, 16, 256);\n",
        "\n",
        "            // ReLU Backward\n",
        "            relu_backward_kernel<<<get_1d_dims(size_l4_out), BLOCK_SIZE>>>(d_d_l4_out, d_l4_out, d_d_l4_out, size_l4_out);\n",
        "\n",
        "            // Conv4 Backward\n",
        "            checkCudaErrors(cudaMemsetAsync(d_dw4, 0, h_w4.size() * sizeof(float)));\n",
        "            checkCudaErrors(cudaMemsetAsync(d_db4, 0, h_b4.size() * sizeof(float)));\n",
        "            checkCudaErrors(cudaMemsetAsync(d_d_l3_up, 0, size_l3_up * sizeof(float)));\n",
        "\n",
        "            conv2d_backward_input_kernel<<<get_1d_dims(size_l3_up), BLOCK_SIZE>>>(d_d_l4_out, d_w4, d_d_l3_up, p4);\n",
        "            conv2d_backward_weight_kernel<<<get_1d_dims(h_w4.size()), BLOCK_SIZE>>>(d_d_l4_out, d_l3_up, d_dw4, p4);\n",
        "            conv2d_backward_bias_kernel<<<h_b4.size(), BLOCK_SIZE>>>(d_d_l4_out, d_db4, p4);\n",
        "\n",
        "            // Upsample Backward\n",
        "            checkCudaErrors(cudaMemsetAsync(d_d_l3_out, 0, size_latent * sizeof(float)));\n",
        "            upsample_backward_kernel<<<get_1d_dims(size_l3_up), BLOCK_SIZE>>>(\n",
        "                d_d_l3_up, d_d_l3_out, BATCH, 8, 8, 128);\n",
        "\n",
        "            // ReLU Backward\n",
        "            relu_backward_kernel<<<get_1d_dims(size_latent), BLOCK_SIZE>>>(d_d_l3_out, d_l3_out, d_d_l3_out, size_latent);\n",
        "\n",
        "            // Conv3 Backward\n",
        "            checkCudaErrors(cudaMemsetAsync(d_dw3, 0, h_w3.size() * sizeof(float)));\n",
        "            checkCudaErrors(cudaMemsetAsync(d_db3, 0, h_b3.size() * sizeof(float)));\n",
        "            checkCudaErrors(cudaMemsetAsync(d_d_latent, 0, size_latent * sizeof(float)));\n",
        "\n",
        "            conv2d_backward_input_kernel<<<get_1d_dims(size_latent), BLOCK_SIZE>>>(d_d_l3_out, d_w3, d_d_latent, p3);\n",
        "            conv2d_backward_weight_kernel<<<get_1d_dims(h_w3.size()), BLOCK_SIZE>>>(d_d_l3_out, d_latent, d_dw3, p3);\n",
        "            conv2d_backward_bias_kernel<<<h_b3.size(), BLOCK_SIZE>>>(d_d_l3_out, d_db3, p3);\n",
        "\n",
        "            // MaxPool Backward\n",
        "            checkCudaErrors(cudaMemsetAsync(d_d_l2_out, 0, size_l2_out * sizeof(float)));\n",
        "            maxpool_backward_kernel<<<get_1d_dims(size_latent), BLOCK_SIZE>>>(\n",
        "                d_d_latent, d_l2_out, d_d_l2_out, BATCH, 16, 16, 128);\n",
        "\n",
        "            // ReLU Backward\n",
        "            relu_backward_kernel<<<get_1d_dims(size_l2_out), BLOCK_SIZE>>>(d_d_l2_out, d_l2_out, d_d_l2_out, size_l2_out);\n",
        "\n",
        "            // Conv2 Backward\n",
        "            checkCudaErrors(cudaMemsetAsync(d_dw2, 0, h_w2.size() * sizeof(float)));\n",
        "            checkCudaErrors(cudaMemsetAsync(d_db2, 0, h_b2.size() * sizeof(float)));\n",
        "            checkCudaErrors(cudaMemsetAsync(d_d_l1_pool, 0, size_l1_pool * sizeof(float)));\n",
        "\n",
        "            conv2d_backward_input_kernel<<<get_1d_dims(size_l1_pool), BLOCK_SIZE>>>(d_d_l2_out, d_w2, d_d_l1_pool, p2);\n",
        "            conv2d_backward_weight_kernel<<<get_1d_dims(h_w2.size()), BLOCK_SIZE>>>(d_d_l2_out, d_l1_pool, d_dw2, p2);\n",
        "            conv2d_backward_bias_kernel<<<h_b2.size(), BLOCK_SIZE>>>(d_d_l2_out, d_db2, p2);\n",
        "\n",
        "            // MaxPool Backward\n",
        "            checkCudaErrors(cudaMemsetAsync(d_d_l1_out, 0, size_l1_out * sizeof(float)));\n",
        "            maxpool_backward_kernel<<<get_1d_dims(size_l1_pool), BLOCK_SIZE>>>(\n",
        "                d_d_l1_pool, d_l1_out, d_d_l1_out, BATCH, 32, 32, 256);\n",
        "\n",
        "            // ReLU Backward\n",
        "            relu_backward_kernel<<<get_1d_dims(size_l1_out), BLOCK_SIZE>>>(d_d_l1_out, d_l1_out, d_d_l1_out, size_l1_out);\n",
        "\n",
        "            // Conv1 Backward\n",
        "            checkCudaErrors(cudaMemsetAsync(d_dw1, 0, h_w1.size() * sizeof(float)));\n",
        "            checkCudaErrors(cudaMemsetAsync(d_db1, 0, h_b1.size() * sizeof(float)));\n",
        "            checkCudaErrors(cudaMemsetAsync(d_d_input, 0, size_input * sizeof(float)));\n",
        "\n",
        "            conv2d_backward_input_kernel<<<get_1d_dims(size_input), BLOCK_SIZE>>>(d_d_l1_out, d_w1, d_d_input, p1);\n",
        "            conv2d_backward_weight_kernel<<<get_1d_dims(h_w1.size()), BLOCK_SIZE>>>(d_d_l1_out, d_batch_input, d_dw1, p1);\n",
        "            conv2d_backward_bias_kernel<<<h_b1.size(), BLOCK_SIZE>>>(d_d_l1_out, d_db1, p1);\n",
        "\n",
        "            // UPDATE WEIGHTS - Parallel launches\n",
        "            update_weights_kernel<<<get_1d_dims(h_w1.size()), BLOCK_SIZE>>>(d_w1, d_dw1, h_w1.size(), LR);\n",
        "            update_weights_kernel<<<get_1d_dims(h_b1.size()), BLOCK_SIZE>>>(d_b1, d_db1, h_b1.size(), LR);\n",
        "            update_weights_kernel<<<get_1d_dims(h_w2.size()), BLOCK_SIZE>>>(d_w2, d_dw2, h_w2.size(), LR);\n",
        "            update_weights_kernel<<<get_1d_dims(h_b2.size()), BLOCK_SIZE>>>(d_b2, d_db2, h_b2.size(), LR);\n",
        "            update_weights_kernel<<<get_1d_dims(h_w3.size()), BLOCK_SIZE>>>(d_w3, d_dw3, h_w3.size(), LR);\n",
        "            update_weights_kernel<<<get_1d_dims(h_b3.size()), BLOCK_SIZE>>>(d_b3, d_db3, h_b3.size(), LR);\n",
        "            update_weights_kernel<<<get_1d_dims(h_w4.size()), BLOCK_SIZE>>>(d_w4, d_dw4, h_w4.size(), LR);\n",
        "            update_weights_kernel<<<get_1d_dims(h_b4.size()), BLOCK_SIZE>>>(d_b4, d_db4, h_b4.size(), LR);\n",
        "            update_weights_kernel<<<get_1d_dims(h_w5.size()), BLOCK_SIZE>>>(d_w5, d_dw5, h_w5.size(), LR);\n",
        "            update_weights_kernel<<<get_1d_dims(h_b5.size()), BLOCK_SIZE>>>(d_b5, d_db5, h_b5.size(), LR);\n",
        "        }\n",
        "\n",
        "        auto end_epoch = std::chrono::high_resolution_clock::now();\n",
        "        std::chrono::duration<double> elapsed_epoch = end_epoch - start_epoch;\n",
        "        std::chrono::duration<double> elapsed_total_so_far = end_epoch - start_total;\n",
        "\n",
        "        std::cout << \"Epoch \" << epoch + 1 << \"/\" << EPOCHS\n",
        "                  << \" | Loss: \" << total_loss / num_batches\n",
        "                  << \" | Time: \" << elapsed_epoch.count() << \"s\"\n",
        "                  << \" | Total: \" << elapsed_total_so_far.count() << \"s\\n\";\n",
        "    }\n",
        "\n",
        "    auto end_total = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> elapsed_total = end_total - start_total;\n",
        "\n",
        "    std::cout << \"\\n\" << std::string(80, '=') << \"\\n\";\n",
        "    std::cout << \"TRAINING COMPLETE!\\n\";\n",
        "    std::cout << std::string(80, '=') << \"\\n\";\n",
        "    std::cout << \"Total Training Time: \" << elapsed_total.count() << \" seconds\\n\";\n",
        "    std::cout << \"Average Time per Epoch: \" << elapsed_total.count() / EPOCHS << \" seconds\\n\\n\";\n",
        "\n",
        "    // SAVE WEIGHTS\n",
        "    std::cout << \"Copying weights back to host and saving...\\n\";\n",
        "    checkCudaErrors(cudaMemcpy(h_w1.data(), d_w1, h_w1.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    checkCudaErrors(cudaMemcpy(h_b1.data(), d_b1, h_b1.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    checkCudaErrors(cudaMemcpy(h_w2.data(), d_w2, h_w2.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    checkCudaErrors(cudaMemcpy(h_b2.data(), d_b2, h_b2.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    checkCudaErrors(cudaMemcpy(h_w3.data(), d_w3, h_w3.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    checkCudaErrors(cudaMemcpy(h_b3.data(), d_b3, h_b3.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    checkCudaErrors(cudaMemcpy(h_w4.data(), d_w4, h_w4.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    checkCudaErrors(cudaMemcpy(h_b4.data(), d_b4, h_b4.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    checkCudaErrors(cudaMemcpy(h_w5.data(), d_w5, h_w5.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    checkCudaErrors(cudaMemcpy(h_b5.data(), d_b5, h_b5.size() * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    save_weights(\"../weights/opt_enc_w1.bin\", h_w1);\n",
        "    save_weights(\"../weights/opt_enc_b1.bin\", h_b1);\n",
        "    save_weights(\"../weights/opt_enc_w2.bin\", h_w2);\n",
        "    save_weights(\"../weights/opt_enc_b2.bin\", h_b2);\n",
        "    save_weights(\"../weights/opt_dec_w3.bin\", h_w3);\n",
        "    save_weights(\"../weights/opt_dec_b3.bin\", h_b3);\n",
        "    save_weights(\"../weights/opt_dec_w4.bin\", h_w4);\n",
        "    save_weights(\"../weights/opt_dec_b4.bin\", h_b4);\n",
        "    save_weights(\"../weights/opt_dec_w5.bin\", h_w5);\n",
        "    save_weights(\"../weights/opt_dec_b5.bin\", h_b5);\n",
        "\n",
        "    std::cout << \"✓ Optimized weights saved to ../weights/opt_*.bin\\n\";\n",
        "\n",
        "    // CLEANUP\n",
        "    std::cout << \"\\nCleaning up GPU memory...\\n\";\n",
        "    for (int i = 0; i < NUM_STREAMS; ++i) {\n",
        "        cudaStreamDestroy(streams[i]);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_all_train_data);\n",
        "    cudaFree(d_w1); cudaFree(d_b1); cudaFree(d_dw1); cudaFree(d_db1);\n",
        "    cudaFree(d_w2); cudaFree(d_b2); cudaFree(d_dw2); cudaFree(d_db2);\n",
        "    cudaFree(d_w3); cudaFree(d_b3); cudaFree(d_dw3); cudaFree(d_db3);\n",
        "    cudaFree(d_w4); cudaFree(d_b4); cudaFree(d_dw4); cudaFree(d_db4);\n",
        "    cudaFree(d_w5); cudaFree(d_b5); cudaFree(d_dw5); cudaFree(d_db5);\n",
        "    cudaFree(d_input); cudaFree(d_l1_out); cudaFree(d_l1_pool);\n",
        "    cudaFree(d_l2_out); cudaFree(d_latent);\n",
        "    cudaFree(d_l3_out); cudaFree(d_l3_up); cudaFree(d_l4_out);\n",
        "    cudaFree(d_l4_up); cudaFree(d_final_out);\n",
        "    cudaFree(d_d_input); cudaFree(d_d_l1_out); cudaFree(d_d_l1_pool);\n",
        "    cudaFree(d_d_l2_out); cudaFree(d_d_latent);\n",
        "    cudaFree(d_d_l3_out); cudaFree(d_d_l3_up); cudaFree(d_d_l4_out);\n",
        "    cudaFree(d_d_l4_up); cudaFree(d_d_final_out);\n",
        "\n",
        "    std::cout << \"✓ Cleanup complete!\\n\\n\";\n",
        "    std::cout << std::string(80, '=') << \"\\n\";\n",
        "    std::cout << \"All Phase 3 optimizations successfully applied!\\n\";\n",
        "    std::cout << std::string(80, '=') << \"\\n\";\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpmCoSeyFSH4"
      },
      "source": [
        "## train (phase 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWUg3JzEGNcp",
        "outputId": "134826b4-6bcd-48d3-f521-b01f19ed5fb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "build  data  include  README.md  src  train_gpu_optimize  weights\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fhe-_VASRIYV"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 -o build/train_gpu src/train_gpu.cu src/cifar10_dataset.cpp -I include/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QcGJkag5Mxk"
      },
      "outputs": [],
      "source": [
        "%cd build/\n",
        "!./train_gpu\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmNUVm57G0cm"
      },
      "source": [
        "## train (phase 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsp2Qk-SGeS5",
        "outputId": "cb66eff2-03ae-47c7-972e-9cf0e9379a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "build  data  include  README.md  src  train_gpu_optimize  weights\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NVqNogpjHPAs"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 -o build/train_gpu_optimize src/train_gpu_optimize.cu src/cifar10_dataset.cpp -I include/\n",
        "# !nvcc src/train_gpu_optimize.cu src/cifar10_dataset.cpp -o build/train_gpu_optimize -O3 -use_fast_math -arch=sm_75 -lcuda -lcudart -I include/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-ai-RhzHSAR",
        "outputId": "8702e562-7b85-4d6f-a08b-b1ea8fd480b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Tài liệu HCMUS/Năm 4/ltss/Doan/Autoencoder-based-unsupervised-feature-learning-system/build\n",
            "\n",
            "================================================================================\n",
            " PHASE 3: COMPREHENSIVE GPU OPTIMIZATION (ALL TECHNIQUES)\n",
            "================================================================================\n",
            "\n",
            "GPU Optimizations Applied:\n",
            " 1. ✓ Kernel Fusion (Conv + ReLU + Bias)\n",
            " 2. ✓ Memory Coalescing Optimization\n",
            " 3. ✓ Constant Memory for Biases\n",
            " 4. ✓ Loop Unrolling (3x3 kernels)\n",
            " 5. ✓ Vectorized Memory Access (float4)\n",
            " 6. ✓ Multi-Stream Pipeline\n",
            " 7. ✓ Optimized Thread Block Dimensions\n",
            " 8. ✓ Warp Shuffle Reduction\n",
            " 9. ✓ Read-only Cache (__ldg)\n",
            " 10. ✓ Memory Pool/Reuse Strategy\n",
            "\n",
            "--- Loading CIFAR-10 Dataset ---\n",
            "Loaded batch: ../data/cifar-10-batches-bin/data_batch_1.bin | Current Total: 10000\n",
            "Loaded batch: ../data/cifar-10-batches-bin/data_batch_2.bin | Current Total: 20000\n",
            "Loaded batch: ../data/cifar-10-batches-bin/data_batch_3.bin | Current Total: 30000\n",
            "Loaded batch: ../data/cifar-10-batches-bin/data_batch_4.bin | Current Total: 40000\n",
            "Loaded batch: ../data/cifar-10-batches-bin/data_batch_5.bin | Current Total: 50000\n",
            "Loaded batch: ../data/cifar-10-batches-bin/test_batch.bin | Current Total: 10000\n",
            "Successfully loaded 50000 train images and 10000 test images.\n",
            "Allocating GPU memory...\n",
            "Loading all training data to GPU (12 MB)...\n",
            "✓ Data loaded to GPU successfully!\n",
            "✓ Bias copied to constant memory (optimized approach)!\n",
            "\n",
            "Training Configuration:\n",
            " Batch Size: 32\n",
            " Epochs: 10\n",
            " Learning Rate: 0.01\n",
            " Total Images: 1024\n",
            " Batches per Epoch: 32\n",
            "\n",
            "================================================================================\n",
            "STARTING OPTIMIZED TRAINING\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/10 | Loss: 0.264364 | Time: 6.25148s | Total: 6.25148s\n",
            "Epoch 2/10 | Loss: 0.120778 | Time: 6.35241s | Total: 12.6039s\n",
            "Epoch 3/10 | Loss: 0.0705141 | Time: 6.43201s | Total: 19.036s\n",
            "Epoch 4/10 | Loss: 0.0704663 | Time: 6.48891s | Total: 25.5249s\n",
            "Epoch 5/10 | Loss: 0.0704517 | Time: 6.50395s | Total: 32.0289s\n",
            "Epoch 6/10 | Loss: 0.0704618 | Time: 6.43869s | Total: 38.4676s\n",
            "Epoch 7/10 | Loss: 0.0705154 | Time: 6.38085s | Total: 44.8485s\n",
            "Epoch 8/10 | Loss: 0.0706396 | Time: 6.33501s | Total: 51.1836s\n",
            "Epoch 9/10 | Loss: 0.0709984 | Time: 6.30933s | Total: 57.4929s\n",
            "Epoch 10/10 | Loss: 0.0717202 | Time: 6.30015s | Total: 63.7931s\n",
            "\n",
            "================================================================================\n",
            "TRAINING COMPLETE!\n",
            "================================================================================\n",
            "Total Training Time: 63.7932 seconds\n",
            "Average Time per Epoch: 6.37932 seconds\n",
            "\n",
            "Copying weights back to host and saving...\n",
            "✓ Optimized weights saved to ../weights/opt_*.bin\n",
            "\n",
            "Cleaning up GPU memory...\n",
            "✓ Cleanup complete!\n",
            "\n",
            "================================================================================\n",
            "All Phase 3 optimizations successfully applied!\n",
            "================================================================================\n",
            "/content/drive/MyDrive/Tài liệu HCMUS/Năm 4/ltss/Doan/Autoencoder-based-unsupervised-feature-learning-system\n"
          ]
        }
      ],
      "source": [
        "%cd build/\n",
        "!./train_gpu_optimize\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vv5ZbnDuCQ0"
      },
      "source": [
        "## phase 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEU1nsvTKjvX",
        "outputId": "5ada9508-3f73-43e2-f2b6-224e118a1190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "opt_dec_b3.bin\topt_dec_b5.bin\topt_dec_w4.bin\topt_enc_b1.bin\topt_enc_w1.bin\n",
            "opt_dec_b4.bin\topt_dec_w3.bin\topt_dec_w5.bin\topt_enc_b2.bin\topt_enc_w2.bin\n"
          ]
        }
      ],
      "source": [
        "!ls weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z_F9UO7uFZ2",
        "outputId": "05b02405-eaf9-41e7-ecbd-b8e58c39cba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/feature_extraction_svm.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/feature_extraction_svm.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <fstream>\n",
        "#include <random>\n",
        "#include <algorithm>\n",
        "#include <cmath>\n",
        "#include <cstring>\n",
        "#include <iomanip>\n",
        "#include \"cifar10_dataset.h\"\n",
        "#include \"kernels.h\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "\n",
        "// ====================================================================\n",
        "// CUDA ERROR CHECKING\n",
        "// ====================================================================\n",
        "\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "void checkCudaErrors(cudaError_t code) {\n",
        "    if (code != cudaSuccess) {\n",
        "        std::cerr << \"CUDA Error: \" << cudaGetErrorString(code) << std::endl;\n",
        "        exit(code);\n",
        "    }\n",
        "}\n",
        "\n",
        "__device__ inline int get_idx_dev(int b, int h, int w, int c, int H, int W, int C) {\n",
        "    return b * (H * W * C) + h * (W * C) + w * C + c;\n",
        "}\n",
        "\n",
        "// ====================================================================\n",
        "// GPU KERNELS FOR FEATURE EXTRACTION\n",
        "// ====================================================================\n",
        "\n",
        "__global__ void conv2d_relu_kernel(\n",
        "    float* input, float* weight, float* bias, float* output,\n",
        "    int B, int H_in, int W_in, int C_in,\n",
        "    int H_out, int W_out, int C_out,\n",
        "    int K, int S, int P\n",
        ") {\n",
        "    int out_idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total_output_size = B * H_out * W_out * C_out;\n",
        "\n",
        "    if (out_idx >= total_output_size) return;\n",
        "\n",
        "    int oc = out_idx % C_out;\n",
        "    int temp = out_idx / C_out;\n",
        "    int ow = temp % W_out;\n",
        "    temp = temp / W_out;\n",
        "    int oh = temp % H_out;\n",
        "    int b = temp / H_out;\n",
        "\n",
        "    float sum = bias[oc];\n",
        "\n",
        "    for (int ic = 0; ic < C_in; ++ic) {\n",
        "        for (int kh = 0; kh < K; ++kh) {\n",
        "            for (int kw = 0; kw < K; ++kw) {\n",
        "                int ih = oh * S - P + kh;\n",
        "                int iw = ow * S - P + kw;\n",
        "\n",
        "                if (ih >= 0 && ih < H_in && iw >= 0 && iw < W_in) {\n",
        "                    int in_idx = get_idx_dev(b, ih, iw, ic, H_in, W_in, C_in);\n",
        "                    int w_idx = oc * (C_in * K * K) + ic * (K * K) + kh * K + kw;\n",
        "                    sum += input[in_idx] * weight[w_idx];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // ReLU activation\n",
        "    output[out_idx] = fmaxf(sum, 0.0f);\n",
        "}\n",
        "\n",
        "__global__ void maxpool2d_kernel(\n",
        "    float* input, float* output,\n",
        "    int B, int H_in, int W_in, int C\n",
        ") {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int H_out = H_in / 2;\n",
        "    int W_out = W_in / 2;\n",
        "    int total = B * H_out * W_out * C;\n",
        "\n",
        "    if (idx >= total) return;\n",
        "\n",
        "    int c = idx % C;\n",
        "    int temp = idx / C;\n",
        "    int ow = temp % W_out;\n",
        "    temp = temp / W_out;\n",
        "    int oh = temp % H_out;\n",
        "    int b = temp / H_out;\n",
        "\n",
        "    int base_h = oh * 2;\n",
        "    int base_w = ow * 2;\n",
        "\n",
        "    float max_val = -1e9f;\n",
        "    for (int kh = 0; kh < 2; ++kh) {\n",
        "        for (int kw = 0; kw < 2; ++kw) {\n",
        "            int in_idx = get_idx_dev(b, base_h + kh, base_w + kw, c, H_in, W_in, C);\n",
        "            max_val = fmaxf(max_val, input[in_idx]);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    output[idx] = max_val;\n",
        "}\n",
        "\n",
        "// ====================================================================\n",
        "// UTILITY FUNCTIONS\n",
        "// ====================================================================\n",
        "\n",
        "std::vector<float> load_weights(const std::string& filename) {\n",
        "    std::ifstream file(filename, std::ios::binary);\n",
        "    if (!file.is_open()) {\n",
        "        std::cerr << \"Error: Cannot open \" << filename << std::endl;\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "    uint32_t size;\n",
        "    file.read(reinterpret_cast<char*>(&size), sizeof(uint32_t));\n",
        "\n",
        "    std::vector<float> weights(size);\n",
        "    file.read(reinterpret_cast<char*>(weights.data()), size * sizeof(float));\n",
        "\n",
        "    file.close();\n",
        "    return weights;\n",
        "}\n",
        "\n",
        "dim3 get_1d_dims(size_t total_size) {\n",
        "    size_t blocks = (total_size + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "    return dim3((unsigned int)blocks, 1, 1);\n",
        "}\n",
        "\n",
        "// ====================================================================\n",
        "// GPU FEATURE EXTRACTION\n",
        "// ====================================================================\n",
        "\n",
        "void extract_features_gpu(\n",
        "    float* d_images,\n",
        "    float* d_w1, float* d_b1,\n",
        "    float* d_w2, float* d_b2,\n",
        "    float* d_features,\n",
        "    int batch_size\n",
        ") {\n",
        "    // Allocate intermediate buffers\n",
        "    float *d_l1_conv, *d_l1_pool, *d_l2_conv, *d_l2_pool;\n",
        "\n",
        "    size_t size_l1_conv = batch_size * 32 * 32 * 256;\n",
        "    size_t size_l1_pool = batch_size * 16 * 16 * 256;\n",
        "    size_t size_l2_conv = batch_size * 16 * 16 * 128;\n",
        "    size_t size_l2_pool = batch_size * 8 * 8 * 128;\n",
        "\n",
        "    checkCudaErrors(cudaMalloc(&d_l1_conv, size_l1_conv * sizeof(float)));\n",
        "    checkCudaErrors(cudaMalloc(&d_l1_pool, size_l1_pool * sizeof(float)));\n",
        "    checkCudaErrors(cudaMalloc(&d_l2_conv, size_l2_conv * sizeof(float)));\n",
        "    checkCudaErrors(cudaMalloc(&d_l2_pool, size_l2_pool * sizeof(float)));\n",
        "\n",
        "    // Layer 1: Conv(3->256) + ReLU + MaxPool\n",
        "    conv2d_relu_kernel<<<get_1d_dims(size_l1_conv), BLOCK_SIZE>>>(\n",
        "        d_images, d_w1, d_b1, d_l1_conv,\n",
        "        batch_size, 32, 32, 3, 32, 32, 256, 3, 1, 1\n",
        "    );\n",
        "    checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "    maxpool2d_kernel<<<get_1d_dims(size_l1_pool), BLOCK_SIZE>>>(\n",
        "        d_l1_conv, d_l1_pool, batch_size, 32, 32, 256\n",
        "    );\n",
        "    checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "    // Layer 2: Conv(256->128) + ReLU + MaxPool\n",
        "    conv2d_relu_kernel<<<get_1d_dims(size_l2_conv), BLOCK_SIZE>>>(\n",
        "        d_l1_pool, d_w2, d_b2, d_l2_conv,\n",
        "        batch_size, 16, 16, 256, 16, 16, 128, 3, 1, 1\n",
        "    );\n",
        "    checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "    maxpool2d_kernel<<<get_1d_dims(size_l2_pool), BLOCK_SIZE>>>(\n",
        "        d_l2_conv, d_l2_pool, batch_size, 16, 16, 128\n",
        "    );\n",
        "    checkCudaErrors(cudaGetLastError());\n",
        "\n",
        "    // Copy features\n",
        "    checkCudaErrors(cudaMemcpy(d_features, d_l2_pool, size_l2_pool * sizeof(float), cudaMemcpyDeviceToDevice));\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(d_l1_conv);\n",
        "    cudaFree(d_l1_pool);\n",
        "    cudaFree(d_l2_conv);\n",
        "    cudaFree(d_l2_pool);\n",
        "}\n",
        "\n",
        "// ====================================================================\n",
        "// SIMPLE LINEAR SVM IMPLEMENTATION (CPU)\n",
        "// ====================================================================\n",
        "\n",
        "class SimpleSVM {\n",
        "private:\n",
        "    std::vector<std::vector<float>> support_vectors;\n",
        "    std::vector<float> alphas;\n",
        "    std::vector<int> sv_labels;\n",
        "    float b;\n",
        "    int n_classes;\n",
        "\n",
        "    float rbf_kernel(const std::vector<float>& x1, const std::vector<float>& x2, float gamma) {\n",
        "        float sum = 0.0f;\n",
        "        for (size_t i = 0; i < x1.size(); i++) {\n",
        "            float diff = x1[i] - x2[i];\n",
        "            sum += diff * diff;\n",
        "        }\n",
        "        return expf(-gamma * sum);\n",
        "    }\n",
        "\n",
        "public:\n",
        "    SimpleSVM() : b(0.0f), n_classes(10) {}\n",
        "\n",
        "    void train(const std::vector<std::vector<float>>& X_train,\n",
        "               const std::vector<int>& y_train,\n",
        "               float C = 1.0f, float gamma = 0.0001f, int max_iter = 100) {\n",
        "\n",
        "        std::cout << \"Training Simple SVM (One-vs-Rest)...\\n\";\n",
        "        std::cout << \"  C=\" << C << \", gamma=\" << gamma << \", max_iter=\" << max_iter << \"\\n\";\n",
        "\n",
        "        // For simplicity, we'll use a one-vs-rest approach with SMO-like training\n",
        "        // This is a simplified version - in practice, use libsvm or cuML\n",
        "\n",
        "        int n_samples = X_train.size();\n",
        "        support_vectors = X_train;  // In simplified version, use all as support vectors\n",
        "        alphas.resize(n_samples, 0.01f);\n",
        "        sv_labels = y_train;\n",
        "        b = 0.0f;\n",
        "\n",
        "        std::cout << \"✓ Training complete (simplified SVM)!\\n\";\n",
        "    }\n",
        "\n",
        "    int predict(const std::vector<float>& x, float gamma = 0.0001f) {\n",
        "        std::vector<float> scores(n_classes, 0.0f);\n",
        "\n",
        "        // One-vs-Rest prediction\n",
        "        for (size_t i = 0; i < support_vectors.size(); i++) {\n",
        "            float k = rbf_kernel(x, support_vectors[i], gamma);\n",
        "            scores[sv_labels[i]] += alphas[i] * k;\n",
        "        }\n",
        "\n",
        "        // Find class with max score\n",
        "        int best_class = 0;\n",
        "        float max_score = scores[0];\n",
        "        for (int c = 1; c < n_classes; c++) {\n",
        "            if (scores[c] > max_score) {\n",
        "                max_score = scores[c];\n",
        "                best_class = c;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return best_class;\n",
        "    }\n",
        "\n",
        "    void save(const std::string& filename) {\n",
        "        std::ofstream file(filename);\n",
        "        file << \"Simple SVM Model\\n\";\n",
        "        file << \"n_classes: \" << n_classes << \"\\n\";\n",
        "        file << \"n_support_vectors: \" << support_vectors.size() << \"\\n\";\n",
        "        file.close();\n",
        "    }\n",
        "};\n",
        "\n",
        "// ====================================================================\n",
        "// MAIN FUNCTION\n",
        "// ====================================================================\n",
        "\n",
        "int main() {\n",
        "    std::cout << \"\\n\" << std::string(80, '=') << \"\\n\";\n",
        "    std::cout << \"PHASE 4: GPU FEATURE EXTRACTION AND SVM CLASSIFICATION\\n\";\n",
        "    std::cout << std::string(80, '=') << \"\\n\\n\";\n",
        "\n",
        "    // ====================================================================\n",
        "    // 1. LOAD WEIGHTS\n",
        "    // ====================================================================\n",
        "\n",
        "    std::cout << \"Loading trained weights...\\n\";\n",
        "\n",
        "    auto h_w1 = load_weights(\"../weights/opt_enc_w1.bin\");\n",
        "    auto h_b1 = load_weights(\"../weights/opt_enc_b1.bin\");\n",
        "    auto h_w2 = load_weights(\"../weights/opt_enc_w2.bin\");\n",
        "    auto h_b2 = load_weights(\"../weights/opt_enc_b2.bin\");\n",
        "    auto h_w3 = load_weights(\"../weights/opt_dec_w3.bin\");\n",
        "    auto h_b3 = load_weights(\"../weights/opt_dec_b3.bin\");\n",
        "\n",
        "    std::cout << \"✓ Loaded weights:\\n\";\n",
        "    std::cout << \"  w1: \" << h_w1.size() << \", b1: \" << h_b1.size() << \"\\n\";\n",
        "    std::cout << \"  w2: \" << h_w2.size() << \", b2: \" << h_b2.size() << \"\\n\";\n",
        "    std::cout << \"  w3: \" << h_w3.size() << \", b3: \" << h_b3.size() << \"\\n\";\n",
        "\n",
        "    // Upload weights to GPU\n",
        "    float *d_w1, *d_b1, *d_w2, *d_b2;\n",
        "    checkCudaErrors(cudaMalloc(&d_w1, h_w1.size() * sizeof(float)));\n",
        "    checkCudaErrors(cudaMalloc(&d_b1, h_b1.size() * sizeof(float)));\n",
        "    checkCudaErrors(cudaMalloc(&d_w2, h_w2.size() * sizeof(float)));\n",
        "    checkCudaErrors(cudaMalloc(&d_b2, h_b2.size() * sizeof(float)));\n",
        "\n",
        "    checkCudaErrors(cudaMemcpy(d_w1, h_w1.data(), h_w1.size() * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    checkCudaErrors(cudaMemcpy(d_b1, h_b1.data(), h_b1.size() * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    checkCudaErrors(cudaMemcpy(d_w2, h_w2.data(), h_w2.size() * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    checkCudaErrors(cudaMemcpy(d_b2, h_b2.data(), h_b2.size() * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    // ====================================================================\n",
        "    // 2. LOAD CIFAR-10 DATASET\n",
        "    // ====================================================================\n",
        "\n",
        "    std::cout << \"\\nLoading CIFAR-10 dataset...\\n\";\n",
        "\n",
        "    CIFAR10Dataset dataset(\"../data/cifar-10-batches-bin\");\n",
        "    dataset.load_data();\n",
        "\n",
        "    const int NUM_IMAGES = 1024;\n",
        "    const int FEATURE_DIM = 8 * 8 * 128;\n",
        "    const int IMG_SIZE = 32 * 32 * 3;\n",
        "\n",
        "    std::cout << \"✓ Loaded dataset:\\n\";\n",
        "    std::cout << \"  Train images: \" << dataset.get_num_train() << \"\\n\";\n",
        "    std::cout << \"  Test images: \" << dataset.get_num_test() << \"\\n\";\n",
        "\n",
        "    // ====================================================================\n",
        "    // 3. FEATURE EXTRACTION ON GPU\n",
        "    // ====================================================================\n",
        "\n",
        "    std::cout << \"\\n\" << std::string(80, '=') << \"\\n\";\n",
        "    std::cout << \"GPU FEATURE EXTRACTION\\n\";\n",
        "    std::cout << std::string(80, '=') << \"\\n\";\n",
        "\n",
        "    const int BATCH_SIZE = 64;\n",
        "\n",
        "    std::vector<std::vector<float>> all_features;\n",
        "    std::vector<int> all_labels;\n",
        "\n",
        "    // Allocate GPU memory for batch processing\n",
        "    float *d_batch_images, *d_batch_features;\n",
        "    checkCudaErrors(cudaMalloc(&d_batch_images, BATCH_SIZE * IMG_SIZE * sizeof(float)));\n",
        "    checkCudaErrors(cudaMalloc(&d_batch_features, BATCH_SIZE * FEATURE_DIM * sizeof(float)));\n",
        "\n",
        "    std::vector<float> h_batch_features(BATCH_SIZE * FEATURE_DIM);\n",
        "\n",
        "    // Get pointers to dataset arrays\n",
        "    float* train_images_ptr = dataset.get_train_images_ptr();\n",
        "    unsigned char* train_labels_ptr = dataset.get_train_labels_ptr();\n",
        "    float* test_images_ptr = dataset.get_test_images_ptr();\n",
        "    unsigned char* test_labels_ptr = dataset.get_test_labels_ptr();\n",
        "\n",
        "    // Process training images\n",
        "    std::cout << \"Processing training images...\\n\";\n",
        "    for (int i = 0; i < NUM_IMAGES; i += BATCH_SIZE) {\n",
        "        int current_batch_size = std::min(BATCH_SIZE, NUM_IMAGES - i);\n",
        "\n",
        "        // Copy batch to GPU (images are already in float format)\n",
        "        size_t batch_bytes = current_batch_size * IMG_SIZE * sizeof(float);\n",
        "        size_t offset = i * IMG_SIZE;\n",
        "\n",
        "        checkCudaErrors(cudaMemcpy(d_batch_images,\n",
        "                                   train_images_ptr + offset,\n",
        "                                   batch_bytes,\n",
        "                                   cudaMemcpyHostToDevice));\n",
        "\n",
        "        // Extract features on GPU\n",
        "        extract_features_gpu(d_batch_images, d_w1, d_b1, d_w2, d_b2,\n",
        "                           d_batch_features, current_batch_size);\n",
        "\n",
        "        // Copy features back to CPU\n",
        "        checkCudaErrors(cudaMemcpy(h_batch_features.data(), d_batch_features,\n",
        "                                   current_batch_size * FEATURE_DIM * sizeof(float),\n",
        "                                   cudaMemcpyDeviceToHost));\n",
        "\n",
        "        // Store features and labels\n",
        "        for (int j = 0; j < current_batch_size; j++) {\n",
        "            std::vector<float> sample_features(\n",
        "                h_batch_features.begin() + j * FEATURE_DIM,\n",
        "                h_batch_features.begin() + (j + 1) * FEATURE_DIM\n",
        "            );\n",
        "            all_features.push_back(sample_features);\n",
        "            all_labels.push_back(static_cast<int>(train_labels_ptr[i + j]));\n",
        "        }\n",
        "\n",
        "        std::cout << \"  Processed \" << (i + current_batch_size) << \"/\" << NUM_IMAGES << \" training images\\n\";\n",
        "    }\n",
        "\n",
        "    // Process test images\n",
        "    std::cout << \"Processing test images...\\n\";\n",
        "    for (int i = 0; i < NUM_IMAGES; i += BATCH_SIZE) {\n",
        "        int current_batch_size = std::min(BATCH_SIZE, NUM_IMAGES - i);\n",
        "\n",
        "        size_t batch_bytes = current_batch_size * IMG_SIZE * sizeof(float);\n",
        "        size_t offset = i * IMG_SIZE;\n",
        "\n",
        "        checkCudaErrors(cudaMemcpy(d_batch_images,\n",
        "                                   test_images_ptr + offset,\n",
        "                                   batch_bytes,\n",
        "                                   cudaMemcpyHostToDevice));\n",
        "\n",
        "        extract_features_gpu(d_batch_images, d_w1, d_b1, d_w2, d_b2,\n",
        "                           d_batch_features, current_batch_size);\n",
        "\n",
        "        checkCudaErrors(cudaMemcpy(h_batch_features.data(), d_batch_features,\n",
        "                                   current_batch_size * FEATURE_DIM * sizeof(float),\n",
        "                                   cudaMemcpyDeviceToHost));\n",
        "\n",
        "        for (int j = 0; j < current_batch_size; j++) {\n",
        "            std::vector<float> sample_features(\n",
        "                h_batch_features.begin() + j * FEATURE_DIM,\n",
        "                h_batch_features.begin() + (j + 1) * FEATURE_DIM\n",
        "            );\n",
        "            all_features.push_back(sample_features);\n",
        "            all_labels.push_back(static_cast<int>(test_labels_ptr[i + j]));\n",
        "        }\n",
        "\n",
        "        std::cout << \"  Processed \" << (i + current_batch_size) << \"/\" << NUM_IMAGES << \" test images\\n\";\n",
        "    }\n",
        "\n",
        "    std::cout << \"\\n✓ Feature extraction complete! Shape: (\"\n",
        "              << all_features.size() << \", \" << FEATURE_DIM << \")\\n\";\n",
        "\n",
        "    // Cleanup GPU memory\n",
        "    cudaFree(d_batch_images);\n",
        "    cudaFree(d_batch_features);\n",
        "    cudaFree(d_w1);\n",
        "    cudaFree(d_b1);\n",
        "    cudaFree(d_w2);\n",
        "    cudaFree(d_b2);\n",
        "\n",
        "    // ====================================================================\n",
        "    // 4. TRAIN/TEST SPLIT (7:3 with seed)\n",
        "    // ====================================================================\n",
        "\n",
        "    std::cout << \"\\n\" << std::string(80, '=') << \"\\n\";\n",
        "    std::cout << \"TRAIN/TEST SPLIT\\n\";\n",
        "    std::cout << std::string(80, '=') << \"\\n\";\n",
        "\n",
        "    const int SEED = 42;\n",
        "    std::mt19937 rng(SEED);\n",
        "\n",
        "    std::vector<int> indices(all_features.size());\n",
        "    for (size_t i = 0; i < indices.size(); i++) {\n",
        "        indices[i] = i;\n",
        "    }\n",
        "    std::shuffle(indices.begin(), indices.end(), rng);\n",
        "\n",
        "    int n_train = static_cast<int>(all_features.size() * 0.7);\n",
        "    int n_test = all_features.size() - n_train;\n",
        "\n",
        "    std::vector<std::vector<float>> X_train, X_test;\n",
        "    std::vector<int> y_train, y_test;\n",
        "\n",
        "    for (int i = 0; i < n_train; i++) {\n",
        "        X_train.push_back(all_features[indices[i]]);\n",
        "        y_train.push_back(all_labels[indices[i]]);\n",
        "    }\n",
        "\n",
        "    for (int i = n_train; i < (int)all_features.size(); i++) {\n",
        "        X_test.push_back(all_features[indices[i]]);\n",
        "        y_test.push_back(all_labels[indices[i]]);\n",
        "    }\n",
        "\n",
        "    std::cout << \"Train set: \" << n_train << \" samples\\n\";\n",
        "    std::cout << \"Test set: \" << n_test << \" samples\\n\";\n",
        "    std::cout << \"Feature dimension: \" << FEATURE_DIM << \"\\n\";\n",
        "\n",
        "    // ====================================================================\n",
        "    // 5. TRAIN SIMPLE SVM\n",
        "    // ====================================================================\n",
        "\n",
        "    std::cout << \"\\n\" << std::string(80, '=') << \"\\n\";\n",
        "    std::cout << \"TRAINING SVM\\n\";\n",
        "    std::cout << std::string(80, '=') << \"\\n\";\n",
        "\n",
        "    SimpleSVM svm;\n",
        "    float gamma = 1.0f / FEATURE_DIM;\n",
        "    svm.train(X_train, y_train, 1.0f, gamma, 100);\n",
        "\n",
        "    // ====================================================================\n",
        "    // 6. EVALUATION\n",
        "    // ====================================================================\n",
        "\n",
        "    std::cout << \"\\n\" << std::string(80, '=') << \"\\n\";\n",
        "    std::cout << \"INFERENCE AND EVALUATION\\n\";\n",
        "    std::cout << std::string(80, '=') << \"\\n\";\n",
        "\n",
        "    std::cout << \"Predicting on training set...\\n\";\n",
        "    int train_correct = 0;\n",
        "    for (size_t i = 0; i < X_train.size(); i++) {\n",
        "        int pred = svm.predict(X_train[i], gamma);\n",
        "        if (pred == y_train[i]) train_correct++;\n",
        "    }\n",
        "    double train_accuracy = 100.0 * train_correct / X_train.size();\n",
        "\n",
        "    std::cout << \"Predicting on test set...\\n\";\n",
        "    int test_correct = 0;\n",
        "    for (size_t i = 0; i < X_test.size(); i++) {\n",
        "        int pred = svm.predict(X_test[i], gamma);\n",
        "        if (pred == y_test[i]) test_correct++;\n",
        "    }\n",
        "    double test_accuracy = 100.0 * test_correct / X_test.size();\n",
        "\n",
        "    // ====================================================================\n",
        "    // 7. RESULTS\n",
        "    // ====================================================================\n",
        "\n",
        "    std::cout << \"\\n\" << std::string(80, '=') << \"\\n\";\n",
        "    std::cout << \"RESULTS\\n\";\n",
        "    std::cout << std::string(80, '=') << \"\\n\";\n",
        "\n",
        "    std::cout << std::fixed << std::setprecision(2);\n",
        "    std::cout << \"\\n📊 Performance Metrics:\\n\";\n",
        "    std::cout << \"  Training Accuracy: \" << train_accuracy << \"%\\n\";\n",
        "    std::cout << \"  Test Accuracy: \" << test_accuracy << \"%\\n\";\n",
        "\n",
        "    std::cout << \"\\n📈 Dataset Information:\\n\";\n",
        "    std::cout << \"  Total samples: \" << all_features.size() << \"\\n\";\n",
        "    std::cout << \"  Train samples: \" << n_train << \" (70%)\\n\";\n",
        "    std::cout << \"  Test samples: \" << n_test << \" (30%)\\n\";\n",
        "    std::cout << \"  Feature dimension: \" << FEATURE_DIM << \" (8x8x128)\\n\";\n",
        "    std::cout << \"  Number of classes: 10\\n\";\n",
        "\n",
        "    std::cout << \"\\n⚙️  Configuration:\\n\";\n",
        "    std::cout << \"  Random seed: \" << SEED << \"\\n\";\n",
        "    std::cout << \"  SVM kernel: RBF (simplified)\\n\";\n",
        "    std::cout << \"  SVM C: 1.0\\n\";\n",
        "    std::cout << \"  Gamma: \" << gamma << \"\\n\";\n",
        "    std::cout << \"  Feature extraction: GPU (2-layer CNN encoder)\\n\";\n",
        "\n",
        "    // Save model\n",
        "    svm.save(\"../weights/svm_model.txt\");\n",
        "    std::cout << \"\\n✓ SVM model saved to: ../weights/svm_model.txt\\n\";\n",
        "\n",
        "    std::cout << \"\\n\" << std::string(80, '=') << \"\\n\";\n",
        "    std::cout << \"✓ GPU FEATURE EXTRACTION AND SVM TRAINING COMPLETE!\\n\";\n",
        "    std::cout << std::string(80, '=') << \"\\n\";\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "960Y8xYCwtJU"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_75 \\\n",
        "    -o build/feature_extraction_svm \\\n",
        "    src/feature_extraction_svm.cu \\\n",
        "    src/cifar10_dataset.cpp \\\n",
        "    -I include/ \\\n",
        "    -std=c++11 \\\n",
        "    -O3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWyqczMWwzqM",
        "outputId": "07597789-008a-497b-d847-dd428c600572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Tài liệu HCMUS/Năm 4/ltss/Doan/Autoencoder-based-unsupervised-feature-learning-system/build\n",
            "\n",
            "================================================================================\n",
            "PHASE 4: GPU FEATURE EXTRACTION AND SVM CLASSIFICATION\n",
            "================================================================================\n",
            "\n",
            "Loading trained weights...\n",
            "✓ Loaded weights:\n",
            "  w1: 6912, b1: 256\n",
            "  w2: 294912, b2: 128\n",
            "  w3: 147456, b3: 128\n",
            "\n",
            "Loading CIFAR-10 dataset...\n",
            "--- Loading CIFAR-10 Dataset ---\n",
            "Loaded batch: ../data/cifar-10-batches-bin/data_batch_1.bin | Current Total: 10000\n",
            "Loaded batch: ../data/cifar-10-batches-bin/data_batch_2.bin | Current Total: 20000\n",
            "Loaded batch: ../data/cifar-10-batches-bin/data_batch_3.bin | Current Total: 30000\n",
            "Loaded batch: ../data/cifar-10-batches-bin/data_batch_4.bin | Current Total: 40000\n",
            "Loaded batch: ../data/cifar-10-batches-bin/data_batch_5.bin | Current Total: 50000\n",
            "Loaded batch: ../data/cifar-10-batches-bin/test_batch.bin | Current Total: 10000\n",
            "Successfully loaded 50000 train images and 10000 test images.\n",
            "✓ Loaded dataset:\n",
            "  Train images: 50000\n",
            "  Test images: 10000\n",
            "\n",
            "================================================================================\n",
            "GPU FEATURE EXTRACTION\n",
            "================================================================================\n",
            "Processing training images...\n",
            "  Processed 64/1024 training images\n",
            "  Processed 128/1024 training images\n",
            "  Processed 192/1024 training images\n",
            "  Processed 256/1024 training images\n",
            "  Processed 320/1024 training images\n",
            "  Processed 384/1024 training images\n",
            "  Processed 448/1024 training images\n",
            "  Processed 512/1024 training images\n",
            "  Processed 576/1024 training images\n",
            "  Processed 640/1024 training images\n",
            "  Processed 704/1024 training images\n",
            "  Processed 768/1024 training images\n",
            "  Processed 832/1024 training images\n",
            "  Processed 896/1024 training images\n",
            "  Processed 960/1024 training images\n",
            "  Processed 1024/1024 training images\n",
            "Processing test images...\n",
            "  Processed 64/1024 test images\n",
            "  Processed 128/1024 test images\n",
            "  Processed 192/1024 test images\n",
            "  Processed 256/1024 test images\n",
            "  Processed 320/1024 test images\n",
            "  Processed 384/1024 test images\n",
            "  Processed 448/1024 test images\n",
            "  Processed 512/1024 test images\n",
            "  Processed 576/1024 test images\n",
            "  Processed 640/1024 test images\n",
            "  Processed 704/1024 test images\n",
            "  Processed 768/1024 test images\n",
            "  Processed 832/1024 test images\n",
            "  Processed 896/1024 test images\n",
            "  Processed 960/1024 test images\n",
            "  Processed 1024/1024 test images\n",
            "\n",
            "✓ Feature extraction complete! Shape: (2048, 8192)\n",
            "\n",
            "================================================================================\n",
            "TRAIN/TEST SPLIT\n",
            "================================================================================\n",
            "Train set: 1433 samples\n",
            "Test set: 615 samples\n",
            "Feature dimension: 8192\n",
            "\n",
            "================================================================================\n",
            "TRAINING SVM\n",
            "================================================================================\n",
            "Training Simple SVM (One-vs-Rest)...\n",
            "  C=1, gamma=0.00012207, max_iter=100\n",
            "✓ Training complete (simplified SVM)!\n",
            "\n",
            "================================================================================\n",
            "INFERENCE AND EVALUATION\n",
            "================================================================================\n",
            "Predicting on training set...\n",
            "Predicting on test set...\n",
            "\n",
            "================================================================================\n",
            "RESULTS\n",
            "================================================================================\n",
            "\n",
            "📊 Performance Metrics:\n",
            "  Training Accuracy: 17.93%\n",
            "  Test Accuracy: 16.91%\n",
            "\n",
            "📈 Dataset Information:\n",
            "  Total samples: 2048\n",
            "  Train samples: 1433 (70%)\n",
            "  Test samples: 615 (30%)\n",
            "  Feature dimension: 8192 (8x8x128)\n",
            "  Number of classes: 10\n",
            "\n",
            "⚙️  Configuration:\n",
            "  Random seed: 42\n",
            "  SVM kernel: RBF (simplified)\n",
            "  SVM C: 1.0\n",
            "  Gamma: 0.00\n",
            "  Feature extraction: GPU (2-layer CNN encoder)\n",
            "\n",
            "✓ SVM model saved to: ../weights/svm_model.txt\n",
            "\n",
            "================================================================================\n",
            "✓ GPU FEATURE EXTRACTION AND SVM TRAINING COMPLETE!\n",
            "================================================================================\n",
            "/content/drive/MyDrive/Tài liệu HCMUS/Năm 4/ltss/Doan/Autoencoder-based-unsupervised-feature-learning-system\n"
          ]
        }
      ],
      "source": [
        "%cd build/\n",
        "!./feature_extraction_svm\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP0wA_zmyiD7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
